{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5665bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:15.106312Z",
     "iopub.status.busy": "2024-05-04T12:46:15.105928Z",
     "iopub.status.idle": "2024-05-04T12:46:30.215101Z",
     "shell.execute_reply": "2024-05-04T12:46:30.213960Z"
    },
    "papermill": {
     "duration": 15.119872,
     "end_time": "2024-05-04T12:46:30.217705",
     "exception": false,
     "start_time": "2024-05-04T12:46:15.097833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lal-ae2-wheel/pyspellchecker-0.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install '/kaggle/input/lal-ae2-wheel/pyspellchecker-0.8.1-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f48ca6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:30.232241Z",
     "iopub.status.busy": "2024-05-04T12:46:30.231842Z",
     "iopub.status.idle": "2024-05-04T12:46:52.672167Z",
     "shell.execute_reply": "2024-05-04T12:46:52.670847Z"
    },
    "papermill": {
     "duration": 22.450171,
     "end_time": "2024-05-04T12:46:52.674523",
     "exception": false,
     "start_time": "2024-05-04T12:46:30.224352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 12:46:40.437179: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-04 12:46:40.437311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-04 12:46:40.585136: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "torch version: 2.1.2\n",
      "transfromers version: 4.39.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from types import SimpleNamespace\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(f'python version: {sys.version}') \n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'transfromers version: {transformers.__version__}')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf29dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:52.689842Z",
     "iopub.status.busy": "2024-05-04T12:46:52.689087Z",
     "iopub.status.idle": "2024-05-04T12:46:52.694934Z",
     "shell.execute_reply": "2024-05-04T12:46:52.693973Z"
    },
    "papermill": {
     "duration": 0.01566,
     "end_time": "2024-05-04T12:46:52.696936",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.681276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\n",
    "def seed_everything(seed: int):    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6728ba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:52.711791Z",
     "iopub.status.busy": "2024-05-04T12:46:52.711072Z",
     "iopub.status.idle": "2024-05-04T12:46:52.924598Z",
     "shell.execute_reply": "2024-05-04T12:46:52.923316Z"
    },
    "papermill": {
     "duration": 0.223884,
     "end_time": "2024-05-04T12:46:52.927351",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.703467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/'\n",
    "# train_df = pd.read_csv(data_path + \"train.csv\")\n",
    "# test_df = pd.read_csv(data_path + \"test.csv\")\n",
    "# samp_df = pd.read_csv(data_path + \"sample_submission.csv\")\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/lal-aes2-create-prompt-data/train_df_non_overlapped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b127991b",
   "metadata": {
    "papermill": {
     "duration": 0.006889,
     "end_time": "2024-05-04T12:46:52.941602",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.934713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2426da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:52.958041Z",
     "iopub.status.busy": "2024-05-04T12:46:52.957088Z",
     "iopub.status.idle": "2024-05-04T12:46:52.970274Z",
     "shell.execute_reply": "2024-05-04T12:46:52.969197Z"
    },
    "papermill": {
     "duration": 0.023755,
     "end_time": "2024-05-04T12:46:52.972494",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.948739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AE2Dataset(Dataset):\n",
    "    def __init__(self, conf, df, tokenizer, output_tokens_only=False):\n",
    "        self.conf = conf\n",
    "        self.full_texts = df[self.conf.train_col].reset_index(drop=True).values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_tokens_only = output_tokens_only\n",
    "        \n",
    "        if not self.output_tokens_only:\n",
    "            self.essay_ids = df['essay_id'].reset_index(drop=True).values\n",
    "            self.labels = df[self.conf.target_col].reset_index(drop=True).values\n",
    "            if self.conf.num_labels == 1: # regression\n",
    "                self.label_dtype = torch.float\n",
    "                if self.conf.criterion == 'bce':\n",
    "                    self.labels = self.labels / 5.0 \n",
    "            else: # classication\n",
    "                self.label_dtype = torch.long\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.full_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self._get_token(idx)\n",
    "        if self.output_tokens_only:\n",
    "            return tokens\n",
    "        else:\n",
    "            ids = self.essay_ids[idx]\n",
    "            labels = self._get_label(idx)\n",
    "        return {'tokens': tokens, 'labels': labels, 'ids': ids}\n",
    "    \n",
    "    def _get_token(self, idx):\n",
    "        tokenized = self.tokenizer(\n",
    "            self.full_texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.conf.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        return {k: torch.tensor(v, dtype=torch.long) for k, v in tokenized.items()}\n",
    "    \n",
    "    def _get_label(self, idx):\n",
    "        return torch.tensor(self.labels[idx], dtype=self.label_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e5232",
   "metadata": {
    "papermill": {
     "duration": 0.006895,
     "end_time": "2024-05-04T12:46:52.986762",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.979867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2b5f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.002668Z",
     "iopub.status.busy": "2024-05-04T12:46:53.002285Z",
     "iopub.status.idle": "2024-05-04T12:46:53.021618Z",
     "shell.execute_reply": "2024-05-04T12:46:53.020722Z"
    },
    "papermill": {
     "duration": 0.029981,
     "end_time": "2024-05-04T12:46:53.023872",
     "exception": false,
     "start_time": "2024-05-04T12:46:52.993891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "class ConcatPooling(nn.Module):\n",
    "    def __init__(self, pooling_last=4):\n",
    "        super().__init__()\n",
    "        self.pooling_last = pooling_last\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        concat_pooling = torch.cat(tuple(all_hidden_states[-l] for l in range(1, self.pooling_last + 1)), -1)\n",
    "        concat_pooling = concat_pooling[:, 0] # select the first one\n",
    "        return concat_pooling\n",
    "    \n",
    "# https://www.kaggle.com/competitions/google-quest-challenge/discussion/129840    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average[:, 0]\n",
    "    \n",
    "# https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently\n",
    "class LSTMPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_lstm):\n",
    "        super().__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_lstm = hiddendim_lstm\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out, _ = self.lstm(hidden_states, None)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45eef5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.040451Z",
     "iopub.status.busy": "2024-05-04T12:46:53.039706Z",
     "iopub.status.idle": "2024-05-04T12:46:53.061556Z",
     "shell.execute_reply": "2024-05-04T12:46:53.060452Z"
    },
    "papermill": {
     "duration": 0.032727,
     "end_time": "2024-05-04T12:46:53.063874",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.031147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, conf, conf_path=None):\n",
    "        super().__init__()\n",
    "        self.conf_path = conf_path\n",
    "        self.multi_dropout = conf.multi_dropout\n",
    "        if not self.conf_path:\n",
    "            self.model_conf = AutoConfig.from_pretrained(conf.model_name, output_hidden_states=True)\n",
    "            self.model_conf = self._set_dropout(self.model_conf)\n",
    "            self.backbone = AutoModel.from_pretrained(conf.model_name, config=self.model_conf)\n",
    "        else:\n",
    "            self.model_conf = torch.load(self.conf_path)\n",
    "            self.backbone = AutoModel.from_config(self.model_conf)\n",
    "        \n",
    "        if conf.gradient_checkpointing:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "        \n",
    "        self.pooler, hidden_size = self.get_pooling_layer(conf)\n",
    "        self.fc = nn.Linear(hidden_size, conf.num_labels)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if self.multi_dropout and conf.num_labels > 1:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "    \n",
    "    def _set_dropout(self, model_conf, ratio=0.):\n",
    "        model_conf.attention_dropout = ratio\n",
    "        model_conf.attention_probs_dropout_prob = ratio\n",
    "        model_conf.hidden_dropout = ratio\n",
    "        model_conf.hidden_dropout_prob = ratio\n",
    "        \n",
    "        return model_conf\n",
    "    \n",
    "    def get_pooling_layer(self, conf):\n",
    "        if conf.pooling_layer == 'mean_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return MeanPooling(), hidden_size\n",
    "        if conf.pooling_layer == 'concat_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size * conf.ccp_pooling_last\n",
    "            return ConcatPooling(conf.ccp_pooling_last), hidden_size\n",
    "        if conf.pooling_layer == 'weighted_layer_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return WeightedLayerPooling(self.model_conf.num_hidden_layers, conf.wlp_layer_start), hidden_size\n",
    "        if conf.pooling_layer == 'lstm_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return LSTMPooling(self.model_conf.num_hidden_layers, hidden_size, conf.lstm_hidden), hidden_size\n",
    "        else:\n",
    "            raise Exception('Invalid pooling layer name')\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        backbone_outputs = self.backbone(**inputs)\n",
    "        pooler_outputs = self.pooler(backbone_outputs, inputs)\n",
    "        if self.multi_dropout:\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    h = self.fc(dropout(pooler_outputs))\n",
    "                else:\n",
    "                    h += self.fc(dropout(pooler_outputs))\n",
    "\n",
    "            outputs = h / len(self.dropouts)\n",
    "        else:\n",
    "            outputs = self.fc(pooler_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d79a13",
   "metadata": {
    "papermill": {
     "duration": 0.006847,
     "end_time": "2024-05-04T12:46:53.078001",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.071154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c016298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.093709Z",
     "iopub.status.busy": "2024-05-04T12:46:53.093320Z",
     "iopub.status.idle": "2024-05-04T12:46:53.100255Z",
     "shell.execute_reply": "2024-05-04T12:46:53.099231Z"
    },
    "papermill": {
     "duration": 0.01753,
     "end_time": "2024-05-04T12:46:53.102609",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.085079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df_):\n",
    "    df = df_.copy()\n",
    "    \n",
    "    drop_id_list = ['e9be80d', '6017fea', 'e9be80d']\n",
    "    \n",
    "    df = df[~df['essay_id'].isin(drop_id_list)].reset_index(drop=True)\n",
    "    \n",
    "                \n",
    "#     labels_map = {\n",
    "#         'Car-free cities': 0,\n",
    "#         '\"A Cowboy Who Rode the Waves\"': 1,\n",
    "#         'Exploring Venus': 2,\n",
    "#         'Facial action coding system': 3,\n",
    "#         'The Face on Mars': 4,\n",
    "#         'Driverless cars': 5,\n",
    "#         'Does the electoral college work?': 6\n",
    "#     }\n",
    "#     df['prompt_name'] = df['prompt_name'].replace(labels_map).astype(int)\n",
    "    \n",
    "    \n",
    "#     df['label'] = df['score'].copy() - 1\n",
    "    df['full_text'] = df['full_text'].str.replace('\\xa0', ' ')\n",
    "    df['full_text'] = df['full_text'].str.replace('\\n', '|')\n",
    "    df['full_text'] = df['full_text'].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48521644",
   "metadata": {
    "papermill": {
     "duration": 0.006976,
     "end_time": "2024-05-04T12:46:53.116946",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.109970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LGBM Preprocess and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ebbbc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.133413Z",
     "iopub.status.busy": "2024-05-04T12:46:53.132996Z",
     "iopub.status.idle": "2024-05-04T12:46:53.366452Z",
     "shell.execute_reply": "2024-05-04T12:46:53.365553Z"
    },
    "papermill": {
     "duration": 0.245029,
     "end_time": "2024-05-04T12:46:53.369239",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.124210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __tokenizer(x):\n",
    "    return x\n",
    "def __preprocessor(x):\n",
    "    return x\n",
    "\n",
    "spell = SpellChecker()\n",
    "def count_spelling_errors(txt):\n",
    "    freq = np.array([spell[word] for word in txt.split(' ')])\n",
    "    misspelled_count = len(freq[freq == 0])\n",
    "    return misspelled_count\n",
    "\n",
    "def data_preprocessing(x, data_type):\n",
    "    pattern_list = [r'<.*?>', '@\\w+', \"'\\d+\", '\\d+', 'http\\w+', r'\\s+', r'\\.+', r'\\,+', '\\xa0']\n",
    "    replace_with_list = ['', '', '', '', '', ' ', '.', ',', ' ']\n",
    "    x = x.with_columns(pl.col(data_type).str.to_lowercase())\n",
    "    x = x.with_columns(pl.col(data_type).str.replace_many(pattern_list, replace_with_list))\n",
    "    x = x.with_columns(pl.col(data_type).str.strip_chars())\n",
    "    \n",
    "    return x\n",
    "\n",
    "def paragraph_preprocess(df):\n",
    "    \n",
    "    df = df.explode('paragraph')\n",
    "    df = data_preprocessing(df, 'paragraph')\n",
    "    df = df.with_columns(pl.col('paragraph').str.replace_all(r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', '').alias('p_no_punctuation'))\n",
    "    df = df.with_columns(pl.col('p_no_punctuation').map_elements(count_spelling_errors, return_dtype=pl.Int64).alias('p_error_num'))\n",
    "    df = df.with_columns(pl.col('paragraph').str.len_chars().alias('p_len'))\n",
    "    df = df.with_columns(pl.col('paragraph').str.count_matches('\\.').alias('p_sentence_count'))\n",
    "    df = df.with_columns(pl.col('paragraph').str.count_matches(' ').alias('p_word_count'))\n",
    "\n",
    "    return df\n",
    "\n",
    "def paragraph_eng(df):\n",
    "    p_features = ['p_error_num', 'p_len', 'p_sentence_count', 'p_word_count']\n",
    "    range_list = np.arange(0, 625, 25)\n",
    "    range_list2 = np.arange(0, 725, 25)\n",
    "    aggs = [\n",
    "        *[pl.col('paragraph').filter(pl.col('p_len') >= l).count().alias(f'p_g{l}_count') for l in range_list],\n",
    "        *[pl.col('paragraph').filter(pl.col('p_len') <= l).count().alias(f'p_l{l}_count') for l in [24, 49]],\n",
    "        *[pl.col(feat).max().alias(f'{feat}_max') for feat in p_features],\n",
    "        *[pl.col(feat).mean().alias(f'{feat}_mean') for feat in p_features],\n",
    "        *[pl.col(feat).min().alias(f'{feat}_min') for feat in p_features],\n",
    "        *[pl.col(feat).sum().alias(f'{feat}_sum') for feat in p_features],\n",
    "        *[pl.col(feat).first().alias(f'{feat}_first') for feat in p_features],\n",
    "        *[pl.col(feat).last().alias(f'{feat}_last') for feat in p_features],\n",
    "        *[pl.col(feat).kurtosis().alias(f'{feat}_kurtosis') for feat in p_features],\n",
    "        *[pl.col(feat).quantile(0.25).alias(f'{feat}_q1') for feat in p_features],\n",
    "        *[pl.col(feat).quantile(0.75).alias(f'{feat}_q3') for feat in p_features],\n",
    "    ]\n",
    "    \n",
    "    df = df.group_by('essay_id', maintain_order=True).agg(aggs)\n",
    "\n",
    "    return df\n",
    "\n",
    "def sentence_preprocess(df):\n",
    "    df = data_preprocessing(df, 'full_text')\n",
    "    df = df.with_columns(pl.col('full_text').str.split('.').alias('sentence'))\n",
    "    df = df.explode('sentence')\n",
    "    df = df.with_columns(pl.col('sentence').str.len_chars().alias('s_len'))\n",
    "    df = df.with_columns(pl.col('sentence').str.count_matches(' ').alias('s_word_count'))\n",
    "    return df\n",
    "\n",
    "def sentence_eng(df):\n",
    "    s_features = ['s_len', 's_word_count']\n",
    "    range_list = np.arange(0, 350, 50)\n",
    "    aggs = [\n",
    "        *[pl.col('sentence').filter(pl.col('s_len') >= l).alias(f's_g{l}_count').count() for l in range_list],\n",
    "        *[pl.col('sentence').filter(pl.col('s_len') <= l).alias(f's_l{l}_count').count() for l in [15]],\n",
    "        *[pl.col(feat).max().alias(f'{feat}_max') for feat in s_features],\n",
    "        *[pl.col(feat).mean().alias(f'{feat}_mean') for feat in s_features],\n",
    "        *[pl.col(feat).min().alias(f'{feat}_min') for feat in s_features],\n",
    "        *[pl.col(feat).sum().alias(f'{feat}_sum') for feat in s_features],\n",
    "        *[pl.col(feat).first().alias(f'{feat}_first') for feat in s_features],\n",
    "        *[pl.col(feat).last().alias(f'{feat}_last') for feat in s_features],\n",
    "        *[pl.col(feat).kurtosis().alias(f'{feat}_kurtosis') for feat in s_features],\n",
    "        *[pl.col(feat).quantile(0.25).alias(f'{feat}_q1') for feat in s_features],\n",
    "        *[pl.col(feat).quantile(0.75).alias(f'{feat}_q3') for feat in s_features],\n",
    "    ]\n",
    "    \n",
    "    df = df.group_by('essay_id', maintain_order=True).agg(aggs)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def word_preprocess(df):\n",
    "    df = data_preprocessing(df, 'full_text')\n",
    "    df = df.with_columns(pl.col('full_text').str.split(' ').alias('word'))\n",
    "    df = df.explode('word')\n",
    "    df = df.with_columns(pl.col('word').str.len_chars().alias('w_len'))\n",
    "    df = df.filter(pl.col('w_len') != 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def word_eng(df):\n",
    "    range_list = np.arange(1, 21)\n",
    "    aggs = [\n",
    "        *[pl.col('word').filter(pl.col('w_len') >= i).count().alias(f'w_{i}_count') for i in range_list],\n",
    "        pl.col('w_len').max().alias('w_len_max'),\n",
    "        pl.col('w_len').mean().alias('w_len_mean'),\n",
    "        pl.col('w_len').std().alias('w_len_std'),\n",
    "        pl.col('w_len').quantile(0.25).alias('w_len_q1'),\n",
    "        pl.col('w_len').quantile(0.50).alias('w_len_q2'),\n",
    "        pl.col('w_len').quantile(0.75).alias('w_len_q3'),\n",
    "    ]\n",
    "    \n",
    "    df = df.group_by('essay_id', maintain_order=True).agg(aggs)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_tfidf_vec_feats(df, vec_path):\n",
    "    tfidf_vec = torch.load(vec_path)\n",
    "    train_tfidf = tfidf_vec.transform([i for i in df['full_text']])\n",
    "    tfidf_dense = train_tfidf.toarray()\n",
    "    tfidf_df = pl.DataFrame(tfidf_dense)\n",
    "    tfidf_columns = [f'tfidf_vec_{i}' for i in range(len(tfidf_df.columns))]\n",
    "    tfidf_df.columns = tfidf_columns\n",
    "    tfidf_df = tfidf_df.with_columns(essay_id=df['essay_id'])\n",
    "    return tfidf_df\n",
    "\n",
    "def get_count_vec_feats(df, vec_path):\n",
    "    count_vec = torch.load(vec_path)\n",
    "    train_count = count_vec.transform([i for i in df['full_text']])\n",
    "    count_dense = train_count.toarray()\n",
    "    count_df = pl.DataFrame(count_dense)\n",
    "    count_columns = [f'count_vec_{i}' for i in range(len(count_df.columns))]\n",
    "    count_df.columns = count_columns\n",
    "    count_df = count_df.with_columns(essay_id=df['essay_id'])\n",
    "    return count_df\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    y_true = y_true + a\n",
    "    y_pred = (y_pred + a).clip(1, 6).round()\n",
    "    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "    return 'QWK', qwk, True\n",
    "def qwk_obj(y_true, y_pred):\n",
    "    labels = y_true + a\n",
    "    preds = y_pred + a\n",
    "    preds = preds.clip(1, 6)\n",
    "    f = 1/2*np.sum((preds-labels)**2)\n",
    "    g = 1/2*np.sum((preds-a)**2+b)\n",
    "    df = preds - labels\n",
    "    dg = preds - a\n",
    "    grad = (df/g - f*dg/g**2)*len(labels)\n",
    "    hess = np.ones(len(labels))\n",
    "    return grad, hess\n",
    "\n",
    "# a = 2.998\n",
    "# b = 1.092\n",
    "\n",
    "# (2.948402380539666, 1.0918134361390224)\n",
    "\n",
    "a = 2.948\n",
    "b = 1.092"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d16da",
   "metadata": {
    "papermill": {
     "duration": 0.007168,
     "end_time": "2024-05-04T12:46:53.383958",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.376790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23867de4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.400857Z",
     "iopub.status.busy": "2024-05-04T12:46:53.400451Z",
     "iopub.status.idle": "2024-05-04T12:46:53.433932Z",
     "shell.execute_reply": "2024-05-04T12:46:53.432866Z"
    },
    "papermill": {
     "duration": 0.045086,
     "end_time": "2024-05-04T12:46:53.436430",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.391344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InferModels:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.models_dict = OrderedDict()\n",
    "        self.lgbm_models_dict = OrderedDict()\n",
    "    \n",
    "    def register(self, model_name, path, fold_num_list):\n",
    "        model_config_dict = self._load_config_path(path, fold_num_list)\n",
    "        self.models_dict[model_name] = model_config_dict\n",
    "        print(f'REGISTERED: {model_name}')\n",
    "        \n",
    "    def register_lgbm(self, model_name, path):\n",
    "        model_config_dict = self._load_lgbm_config_path(path)\n",
    "        self.lgbm_models_dict[model_name] = model_config_dict\n",
    "        print(f'REGISTERED: {model_name}')\n",
    "    \n",
    "    def predict_cv(self, test_df):\n",
    "        \n",
    "        test_df = preprocess_data(test_df)\n",
    "        \n",
    "        for model_name, model_config_dict in self.models_dict.items():\n",
    "\n",
    "            with open(model_config_dict['yaml']) as file:\n",
    "                conf = SimpleNamespace(**yaml.safe_load(file))\n",
    "                \n",
    "            seed_everything(conf.seed)\n",
    "            \n",
    "            model_config_path = model_config_dict['model_config']\n",
    "            tokenizer = self._get_tokenizer(model_config_dict['tokenizer'])\n",
    "            \n",
    "            fold_predictions_list = []\n",
    "            fold_raw_predictions_list = []\n",
    "            essay_id_df = test_df['essay_id']\n",
    "            \n",
    "            for fold_num, model_path in model_config_dict['models'].items():\n",
    "                print(f'INFERENCING: {model_name}, CONFIG_EXP: {conf.exp}, FOLD: {fold_num}')\n",
    "                \n",
    "                model = self._load_model(conf, model_config_path, model_path)\n",
    "                test_dataloader = self._get_test_dataloader(conf, test_df, tokenizer)\n",
    "                fold_predictions, fold_raw_predictions = self._predict(conf, model, test_dataloader)\n",
    "                fold_predictions_list.append(fold_predictions.squeeze())\n",
    "            \n",
    "            fold_preds_array = np.rint(torch.stack(fold_predictions_list).cpu().numpy())\n",
    "            fold_preds_array = {f'class_f{f}': i for f, i in enumerate(fold_preds_array)}\n",
    "            \n",
    "            cv_df = pd.DataFrame(fold_preds_array)\n",
    "            cv_df = pd.concat([essay_id_df, cv_df], axis=1)\n",
    "            \n",
    "            self.models_dict[model_name]['cv_df'] = cv_df\n",
    "        \n",
    "    def ensemble(self, method='mean'): # method need works, when weights needs\n",
    "        model_pred_df_list = [\n",
    "            v['cv_df'][['essay_id'] + [f'class_f{i}' for i in range(len(v['models']))]]\n",
    "            for v in self.models_dict.values()\n",
    "        ]\n",
    "        essay_id_df = model_pred_df_list[0]['essay_id']\n",
    "        pred_values = [np.mean(df.drop('essay_id', axis=1).values, axis=1) for df in model_pred_df_list]\n",
    "        \n",
    "        if method == 'mean':\n",
    "            pred_mean = np.mean(pred_values, axis=0).clip(0, 6) # take mean across all models and clip to [1, 6]\n",
    "            pred_df = pd.DataFrame(pred_mean, columns=['class'])\n",
    "            \n",
    "        elif isinstance(method, list) and len(method) == (len(self.models_dict) + len(self.lgbm_models_dict)):\n",
    "            weighted_pred = np.average(pred_values, axis=0, weights=method)\n",
    "            pred_df = pd.DataFrame(weighted_pred, columns['class'])\n",
    "            \n",
    "        else:\n",
    "            raise Exception('method is invalid')\n",
    "            \n",
    "        result = pd.concat([essay_id_df, pred_df], axis=1)\n",
    "        result['class'] = result['class'].astype(int)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def _predict(self, conf, model, dataloader):\n",
    "        raw_predictions = []\n",
    "        predictions = []\n",
    "        \n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "\n",
    "        for inputs in tqdm(dataloader):\n",
    "\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                raw_outputs = model(inputs)\n",
    "            \n",
    "            outputs = self._process_outputs(conf, raw_outputs)\n",
    "            raw_predictions.append(raw_outputs)\n",
    "            predictions.append(outputs.float())\n",
    "        \n",
    "        raw_predictions = torch.stack(raw_predictions)\n",
    "        predictions = torch.stack(predictions)\n",
    "        \n",
    "        return predictions, raw_predictions\n",
    "    \n",
    "    def _process_outputs(self, conf, outputs):\n",
    "        if conf.num_labels == 1:\n",
    "            ouputs = outputs.squeeze()\n",
    "        else:\n",
    "            outputs = outputs.softmax(1).argmax(-1)\n",
    "        \n",
    "        if conf.criterion == 'bce':\n",
    "            outputs = outputs.sigmoid() * 5.0\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def _get_tokenizer(self, tokenizer_path):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        return tokenizer\n",
    "    \n",
    "    def _load_config_path(self, path, fold_num_list):\n",
    "        # /kaggle/input/fb-debertav3-roberta-large-seed0/exp54s0/best-epoch-fold3.pt\n",
    "        config_dict = {\n",
    "            'yaml': f'{path}/config.yaml',\n",
    "            'model_config': list(Path(path).glob('*_config.pt'))[0].as_posix(),\n",
    "            'tokenizer': f'{path}/tokenizers/',\n",
    "            'models': {f: f'{path}/best_score_fold{f}.pt' for f in fold_num_list},\n",
    "            'oof_df': f'{path}/oof_df.csv'\n",
    "        }\n",
    "        return config_dict\n",
    "    \n",
    "    def _load_lgbm_config_path(self, path):\n",
    "        config_dict = {\n",
    "            'models': f'{path}/models.bin',\n",
    "            'selected_feats': f'{path}/selected_feats.yaml',\n",
    "            'vectors': {\n",
    "                'tf-idf': f'{path}/tfidf_vec.bin',\n",
    "                'count': f'{path}/count_vec.bin'\n",
    "            }\n",
    "        }\n",
    "        return config_dict\n",
    "    \n",
    "    def _load_model(self, conf, model_config_path, pretrained_model_path):\n",
    "        model = CustomModel(conf, conf_path=model_config_path)\n",
    "        state_dict = torch.load(pretrained_model_path, map_location=self.device)['model_state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "    \n",
    "    def _get_test_dataloader(self, conf, df, tokenizer, batch_num=1):\n",
    "        test_dataset = AE2Dataset(conf, df, tokenizer, output_tokens_only=True)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_num,\n",
    "            num_workers=0,\n",
    "            collate_fn= DataCollatorWithPadding(tokenizer=tokenizer, padding='longest'),\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        return test_dataloader\n",
    "        \n",
    "    def print_registered_models(self):\n",
    "        for model_name in self.models_dict.keys():\n",
    "            print(model_name)\n",
    "        for model_name in self.lgbm_models_dict.keys():\n",
    "            print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afb0c7",
   "metadata": {
    "papermill": {
     "duration": 0.006831,
     "end_time": "2024-05-04T12:46:53.451446",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.444615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9443c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.468579Z",
     "iopub.status.busy": "2024-05-04T12:46:53.467651Z",
     "iopub.status.idle": "2024-05-04T12:46:53.472515Z",
     "shell.execute_reply": "2024-05-04T12:46:53.471462Z"
    },
    "papermill": {
     "duration": 0.015762,
     "end_time": "2024-05-04T12:46:53.474721",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.458959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18272fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.491729Z",
     "iopub.status.busy": "2024-05-04T12:46:53.490844Z",
     "iopub.status.idle": "2024-05-04T12:46:53.561938Z",
     "shell.execute_reply": "2024-05-04T12:46:53.560755Z"
    },
    "papermill": {
     "duration": 0.082175,
     "end_time": "2024-05-04T12:46:53.564389",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.482214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTERED: PROMPT_02\n"
     ]
    }
   ],
   "source": [
    "infermodels = InferModels()\n",
    "infermodels.register('PROMPT_02', '/kaggle/input/lal-aes2-train-prompt-name', [0, 1, 2])\n",
    "# infermodels.register('exp022', '/kaggle/input/lal-aes2-exp022', [0, 1, 2, 3])\n",
    "\n",
    "# infermodels.print_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f9fa1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T12:46:53.581854Z",
     "iopub.status.busy": "2024-05-04T12:46:53.581099Z",
     "iopub.status.idle": "2024-05-04T12:56:50.469877Z",
     "shell.execute_reply": "2024-05-04T12:56:50.468872Z"
    },
    "papermill": {
     "duration": 596.900207,
     "end_time": "2024-05-04T12:56:50.472428",
     "exception": false,
     "start_time": "2024-05-04T12:46:53.572221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCING: PROMPT_02, CONFIG_EXP: PROMPT_02, FOLD: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496b87926e42432c9b89c3a421febbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCING: PROMPT_02, CONFIG_EXP: PROMPT_02, FOLD: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca05c54274f74dca91996522d84c799a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCING: PROMPT_02, CONFIG_EXP: PROMPT_02, FOLD: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1933f24ebc9493cbcd5dbf25a104090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033037</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0065bd6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>ffbd0b4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>ffcb061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>ffcb264</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>ffd378d</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>fffed3e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     essay_id  class\n",
       "0     000fe60      4\n",
       "1     001ab80      5\n",
       "2     001bdc0      2\n",
       "3     0033037      3\n",
       "4     0065bd6      5\n",
       "...       ...    ...\n",
       "4429  ffbd0b4      2\n",
       "4430  ffcb061      1\n",
       "4431  ffcb264      3\n",
       "4432  ffd378d      2\n",
       "4433  fffed3e      2\n",
       "\n",
       "[4434 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infermodels.predict_cv(test_df)\n",
    "\n",
    "pred_df = infermodels.ensemble(method='mean')\n",
    "if submit:\n",
    "    display(pred_df)\n",
    "    pred_df.to_csv('train_df_with_pred_prompt.csv', index=False)\n",
    "\n",
    "# lgbm_pred_df = infermodels.predict_cv_ensemble_lgbm(test_df)\n",
    "# if submit:\n",
    "#     display(lgbm_pred_df)\n",
    "#     lgbm_pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a61b9f",
   "metadata": {
    "papermill": {
     "duration": 0.008376,
     "end_time": "2024-05-04T12:56:50.489282",
     "exception": false,
     "start_time": "2024-05-04T12:56:50.480906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4889847,
     "sourceId": 8242781,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4890316,
     "sourceId": 8299839,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4848281,
     "sourceId": 8298369,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 175625579,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 175608699,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.638519,
   "end_time": "2024-05-04T12:56:53.608947",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-04T12:46:11.970428",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1392315a03844c718a85f48d9d7b1c4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19ed79da278343f98669376110ecb99c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "258354433c074cf58cb6b10a91a7daa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "324869fff10141008a47e2914d11ebfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40378f1f749f4d2082442625d9196bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "442d392a667e45cead953c686b22d653": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "44847de0036442c9bf4f006ec989f1fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "496b87926e42432c9b89c3a421febbce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6250e1924e5d42569aa127b5bff1712c",
        "IPY_MODEL_e7aa288ab5564c7abe2ce4b1466a462d",
        "IPY_MODEL_b50da161bcbe4b74b33fdd567b97643a"
       ],
       "layout": "IPY_MODEL_ca422ba952e3453bb80d9db857eafe64"
      }
     },
     "5204db2189f44c50a0f37e1711184641": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d150c4fef544fd395dda0fb10ee0c92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6250e1924e5d42569aa127b5bff1712c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5204db2189f44c50a0f37e1711184641",
       "placeholder": "​",
       "style": "IPY_MODEL_19ed79da278343f98669376110ecb99c",
       "value": "100%"
      }
     },
     "6585dc95b387494fa31932545a26f367": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7582f46cbebd46c1ad7e12e7c917a70b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c7835f3faab489691bc3871e07c2e21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81e0706dc2f741bcaf7137787f6df716": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93b4b8eb817e4588a4a5f891a347a5b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6900d354c704aff9798005638c56050",
       "placeholder": "​",
       "style": "IPY_MODEL_6585dc95b387494fa31932545a26f367",
       "value": "100%"
      }
     },
     "93f4d60680bf4d21861b304c5ce0a354": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a194c509bc2943d78c0d5df7fe57851d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a6fb2362e29843b593b732766b02f591": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec4f744e9da749008a42c3f38888c5ad",
       "max": 4434.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b0bac9a2b7d442678bd5c473d8907f2d",
       "value": 4434.0
      }
     },
     "ab620b6fd72647d48e9c07c7ac63650e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_324869fff10141008a47e2914d11ebfa",
       "placeholder": "​",
       "style": "IPY_MODEL_258354433c074cf58cb6b10a91a7daa4",
       "value": " 4434/4434 [03:10&lt;00:00, 23.37it/s]"
      }
     },
     "b005c422f21641028cd878851c992487": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81e0706dc2f741bcaf7137787f6df716",
       "max": 4434.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a194c509bc2943d78c0d5df7fe57851d",
       "value": 4434.0
      }
     },
     "b0bac9a2b7d442678bd5c473d8907f2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b50da161bcbe4b74b33fdd567b97643a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1392315a03844c718a85f48d9d7b1c4a",
       "placeholder": "​",
       "style": "IPY_MODEL_5d150c4fef544fd395dda0fb10ee0c92",
       "value": " 4434/4434 [03:11&lt;00:00, 23.36it/s]"
      }
     },
     "bc6abca0ab71462f9936834768b24a50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c1933f24ebc9493cbcd5dbf25a104090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dd0c0d81c5294f0f904fb048c8016716",
        "IPY_MODEL_b005c422f21641028cd878851c992487",
        "IPY_MODEL_cd3a9e4daf0c4df78049e19d02dc83a1"
       ],
       "layout": "IPY_MODEL_93f4d60680bf4d21861b304c5ce0a354"
      }
     },
     "ca05c54274f74dca91996522d84c799a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_93b4b8eb817e4588a4a5f891a347a5b8",
        "IPY_MODEL_a6fb2362e29843b593b732766b02f591",
        "IPY_MODEL_ab620b6fd72647d48e9c07c7ac63650e"
       ],
       "layout": "IPY_MODEL_bc6abca0ab71462f9936834768b24a50"
      }
     },
     "ca422ba952e3453bb80d9db857eafe64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cd3a9e4daf0c4df78049e19d02dc83a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7582f46cbebd46c1ad7e12e7c917a70b",
       "placeholder": "​",
       "style": "IPY_MODEL_dd0797282ccc4a61ad485be016b79892",
       "value": " 4434/4434 [03:10&lt;00:00, 23.26it/s]"
      }
     },
     "d6900d354c704aff9798005638c56050": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd0797282ccc4a61ad485be016b79892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dd0c0d81c5294f0f904fb048c8016716": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_44847de0036442c9bf4f006ec989f1fb",
       "placeholder": "​",
       "style": "IPY_MODEL_442d392a667e45cead953c686b22d653",
       "value": "100%"
      }
     },
     "e7aa288ab5564c7abe2ce4b1466a462d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c7835f3faab489691bc3871e07c2e21",
       "max": 4434.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_40378f1f749f4d2082442625d9196bb7",
       "value": 4434.0
      }
     },
     "ec4f744e9da749008a42c3f38888c5ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
