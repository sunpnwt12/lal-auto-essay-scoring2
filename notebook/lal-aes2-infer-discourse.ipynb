{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d087403",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-15T09:39:40.277102Z",
     "iopub.status.busy": "2024-06-15T09:39:40.276231Z",
     "iopub.status.idle": "2024-06-15T09:40:01.609334Z",
     "shell.execute_reply": "2024-06-15T09:40:01.608476Z"
    },
    "papermill": {
     "duration": 21.344155,
     "end_time": "2024-06-15T09:40:01.611601",
     "exception": false,
     "start_time": "2024-06-15T09:39:40.267446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 09:39:50.027917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-15 09:39:50.028022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-15 09:39:50.165104: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "torch version: 2.1.2\n",
      "transfromers version: 4.39.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from types import SimpleNamespace\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(f'python version: {sys.version}') \n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'transfromers version: {transformers.__version__}')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a08acdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.626471Z",
     "iopub.status.busy": "2024-06-15T09:40:01.626163Z",
     "iopub.status.idle": "2024-06-15T09:40:01.631522Z",
     "shell.execute_reply": "2024-06-15T09:40:01.630635Z"
    },
    "papermill": {
     "duration": 0.014738,
     "end_time": "2024-06-15T09:40:01.633348",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.618610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\n",
    "def seed_everything(seed: int):    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9b490f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.648021Z",
     "iopub.status.busy": "2024-06-15T09:40:01.647723Z",
     "iopub.status.idle": "2024-06-15T09:40:01.660234Z",
     "shell.execute_reply": "2024-06-15T09:40:01.659356Z"
    },
    "papermill": {
     "duration": 0.022151,
     "end_time": "2024-06-15T09:40:01.662332",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.640181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2/'\n",
    "# train_df = pd.read_csv(data_path + \"train.csv\")\n",
    "test_df = pd.read_csv(data_path + \"test.csv\")\n",
    "# samp_df = pd.read_csv(data_path + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a263f96",
   "metadata": {
    "papermill": {
     "duration": 0.006476,
     "end_time": "2024-06-15T09:40:01.675804",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.669328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f6892b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.691140Z",
     "iopub.status.busy": "2024-06-15T09:40:01.690459Z",
     "iopub.status.idle": "2024-06-15T09:40:01.701710Z",
     "shell.execute_reply": "2024-06-15T09:40:01.700797Z"
    },
    "papermill": {
     "duration": 0.021075,
     "end_time": "2024-06-15T09:40:01.703641",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.682566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AE2Dataset(Dataset):\n",
    "    def __init__(self, conf, df, tokenizer, output_tokens_only=False):\n",
    "        self.conf = conf\n",
    "        self.full_texts = df[self.conf.train_col].reset_index(drop=True).values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_tokens_only = output_tokens_only\n",
    "        \n",
    "        if not self.output_tokens_only:\n",
    "            self.essay_ids = df['essay_id'].reset_index(drop=True).values\n",
    "            self.labels = df[self.conf.target_col].reset_index(drop=True).values\n",
    "            if self.conf.num_labels == 1: # regression\n",
    "                self.label_dtype = torch.float\n",
    "                if self.conf.criterion == 'bce':\n",
    "                    self.labels = self.labels / 5.0 \n",
    "            else: # classication\n",
    "                self.label_dtype = torch.long\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.full_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self._get_token(idx)\n",
    "        if self.output_tokens_only:\n",
    "            return tokens\n",
    "        else:\n",
    "            ids = self.essay_ids[idx]\n",
    "            labels = self._get_label(idx)\n",
    "        return {'tokens': tokens, 'labels': labels, 'ids': ids}\n",
    "    \n",
    "    def _get_token(self, idx):\n",
    "        tokenized = self.tokenizer(\n",
    "            self.full_texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.conf.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        return {k: torch.tensor(v, dtype=torch.long) for k, v in tokenized.items()}\n",
    "    \n",
    "    def _get_label(self, idx):\n",
    "        return torch.tensor(self.labels[idx], dtype=self.label_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bb31f5",
   "metadata": {
    "papermill": {
     "duration": 0.006672,
     "end_time": "2024-06-15T09:40:01.718340",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.711668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f397d760",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.733745Z",
     "iopub.status.busy": "2024-06-15T09:40:01.733418Z",
     "iopub.status.idle": "2024-06-15T09:40:01.753377Z",
     "shell.execute_reply": "2024-06-15T09:40:01.752480Z"
    },
    "papermill": {
     "duration": 0.03011,
     "end_time": "2024-06-15T09:40:01.755260",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.725150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "class ConcatPooling(nn.Module):\n",
    "    def __init__(self, pooling_last=4):\n",
    "        super().__init__()\n",
    "        self.pooling_last = pooling_last\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        concat_pooling = torch.cat(tuple(all_hidden_states[-l] for l in range(1, self.pooling_last + 1)), -1)\n",
    "        concat_pooling = concat_pooling[:, 0] # select the first one\n",
    "        return concat_pooling\n",
    "    \n",
    "# https://www.kaggle.com/competitions/google-quest-challenge/discussion/129840    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average[:, 0]\n",
    "    \n",
    "# https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently\n",
    "class LSTMPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_lstm):\n",
    "        super().__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_lstm = hiddendim_lstm\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out, _ = self.lstm(hidden_states, None)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class GeMPooling(nn.Module):\n",
    "    def __init__(self, dim=1, cfg=None, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "        self.feat_mult = 1\n",
    "        # x seeems last hidden state\n",
    "\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.shape)\n",
    "        last_hidden_state = (last_hidden_state.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n",
    "        ret = last_hidden_state / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n",
    "        ret = ret.pow(1 / self.p)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90304581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.769738Z",
     "iopub.status.busy": "2024-06-15T09:40:01.769472Z",
     "iopub.status.idle": "2024-06-15T09:40:01.789444Z",
     "shell.execute_reply": "2024-06-15T09:40:01.788729Z"
    },
    "papermill": {
     "duration": 0.029279,
     "end_time": "2024-06-15T09:40:01.791200",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.761921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, conf, conf_path=None):\n",
    "        super().__init__()\n",
    "        self.conf_path = conf_path\n",
    "        self.multi_dropout = conf.multi_dropout\n",
    "        if not self.conf_path:\n",
    "            self.model_conf = AutoConfig.from_pretrained(conf.model_name, output_hidden_states=True)\n",
    "            self.model_conf = self._set_dropout(self.model_conf)\n",
    "            self.backbone = AutoModel.from_pretrained(conf.model_name, config=self.model_conf)\n",
    "        else:\n",
    "            self.model_conf = torch.load(self.conf_path)\n",
    "            self.backbone = AutoModel.from_config(self.model_conf)\n",
    "        \n",
    "        if conf.gradient_checkpointing:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "            \n",
    "        if conf.freeze_embeddings:\n",
    "            self._freeze(self.backbone.embeddings)\n",
    "            \n",
    "        if conf.freeze_n_layers > 0:\n",
    "            self._freeze(self.backbone.encoder.layer[: conf.freeze_n_layers])\n",
    "        \n",
    "        self.pooler, hidden_size = self.get_pooling_layer(conf)\n",
    "        self.fc = nn.Linear(hidden_size, conf.num_labels)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if self.multi_dropout and conf.num_labels > 1:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "    \n",
    "    def _set_dropout(self, model_conf, ratio=0.):\n",
    "        model_conf.attention_dropout = ratio\n",
    "        model_conf.attention_probs_dropout_prob = ratio\n",
    "        model_conf.hidden_dropout = ratio\n",
    "        model_conf.hidden_dropout_prob = ratio\n",
    "        \n",
    "        return model_conf\n",
    "    \n",
    "    def _freeze(self, module):\n",
    "        for parameter in module.parameters():\n",
    "            parameter.require_grad = False\n",
    "    \n",
    "    def get_pooling_layer(self, conf):\n",
    "        if conf.pooling_layer == 'mean_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return MeanPooling(), hidden_size\n",
    "        if conf.pooling_layer == 'concat_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size * conf.ccp_pooling_last\n",
    "            return ConcatPooling(conf.ccp_pooling_last), hidden_size\n",
    "        if conf.pooling_layer == 'weighted_layer_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return WeightedLayerPooling(self.model_conf.num_hidden_layers, conf.wlp_layer_start), hidden_size\n",
    "        if conf.pooling_layer == 'lstm_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return LSTMPooling(self.model_conf.num_hidden_layers, hidden_size, conf.lstm_hidden), hidden_size\n",
    "        if conf.pooling_layer == 'gem_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return GeMPooling(), hidden_size\n",
    "        else:\n",
    "            raise Exception('Invalid pooling layer name')\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        backbone_outputs = self.backbone(**inputs)\n",
    "        pooler_outputs = self.pooler(backbone_outputs, inputs)\n",
    "        if self.multi_dropout:\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    h = self.fc(dropout(pooler_outputs))\n",
    "                else:\n",
    "                    h += self.fc(dropout(pooler_outputs))\n",
    "\n",
    "            outputs = h / len(self.dropouts)\n",
    "        else:\n",
    "            outputs = self.fc(pooler_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32baaba",
   "metadata": {
    "papermill": {
     "duration": 0.006587,
     "end_time": "2024-06-15T09:40:01.804375",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.797788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c0a348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.819127Z",
     "iopub.status.busy": "2024-06-15T09:40:01.818827Z",
     "iopub.status.idle": "2024-06-15T09:40:01.824792Z",
     "shell.execute_reply": "2024-06-15T09:40:01.823924Z"
    },
    "papermill": {
     "duration": 0.015726,
     "end_time": "2024-06-15T09:40:01.826750",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.811024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "#     df['label'] = df['score'].copy() - 1\n",
    "    df['full_text'] = df['full_text'].str.replace('\\xa0', ' ')\n",
    "#     df['full_text'] = df['full_text'].str.replace('\\n\\n', '[PARAGRAPH]')\n",
    "    df['full_text'] = df['full_text'].str.strip()\n",
    "    return df\n",
    "\n",
    "def collator(inputs):\n",
    "    mask_len = int(inputs['attention_mask'].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902822fd",
   "metadata": {
    "papermill": {
     "duration": 0.006546,
     "end_time": "2024-06-15T09:40:01.840857",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.834311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03d0d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.855909Z",
     "iopub.status.busy": "2024-06-15T09:40:01.855598Z",
     "iopub.status.idle": "2024-06-15T09:40:01.884015Z",
     "shell.execute_reply": "2024-06-15T09:40:01.883207Z"
    },
    "papermill": {
     "duration": 0.038458,
     "end_time": "2024-06-15T09:40:01.885987",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.847529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InferModels:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.models_dict = OrderedDict()\n",
    "        self.lgbm_models_dict = OrderedDict()\n",
    "    \n",
    "    def register(self, model_name, path, fold_num_list):\n",
    "        model_config_dict = self._load_config_path(path, fold_num_list)\n",
    "        self.models_dict[model_name] = model_config_dict\n",
    "        print(f'REGISTERED: {model_name}')\n",
    "\n",
    "    def predict_cv(self, test_df):\n",
    "        \n",
    "        test_df = preprocess_data(test_df)\n",
    "        hold_df = test_df['essay_id']\n",
    "        \n",
    "        for model_name, model_config_dict in self.models_dict.items():\n",
    "\n",
    "            with open(model_config_dict['yaml']) as file:\n",
    "                conf = SimpleNamespace(**yaml.safe_load(file))\n",
    "                \n",
    "            seed_everything(conf.seed)\n",
    "            \n",
    "            model_config_path = model_config_dict['model_config']\n",
    "            tokenizer = self._get_tokenizer(model_config_dict['tokenizer'])\n",
    "            \n",
    "            fold_raw_predictions_list = []\n",
    "            essay_id_df = test_df['essay_id']\n",
    "            \n",
    "            for fold_num, model_path in model_config_dict['models'].items():\n",
    "                print(f'INFERENCING: {model_name}, CONFIG_EXP: {conf.exp}, FOLD: {fold_num}')\n",
    "                \n",
    "                model = self._load_model(conf, model_config_path, model_path, tokenizer)\n",
    "                test_dataloader = self._get_test_dataloader(conf, test_df, tokenizer)\n",
    "                fold_raw_predictions = self._predict(conf, model, test_dataloader)\n",
    "                fold_raw_predictions_list.append(fold_raw_predictions)\n",
    "            \n",
    "            if conf.criterion == 'mse':\n",
    "                fold_mean_raw = np.mean(fold_raw_predictions_list, axis=0) + 1\n",
    "                cv_df = pd.concat([hold_df, pd.DataFrame(fold_mean_raw, columns=['raw_preds'])], axis=1)\n",
    "                \n",
    "            elif conf.criterion == 'ce':\n",
    "                fold_mean_raw = np.mean(fold_raw_predictions_list, axis=0)\n",
    "                fold_mean_raw_df = pd.DataFrame(fold_mean_raw, columns=[f'pred_class_{c}' for c in range(conf.num_labels)])\n",
    "                cv_df = pd.concat([hold_df, fold_mean_raw_df], axis=1)\n",
    "\n",
    "            self.models_dict[model_name]['cv_df'] = cv_df\n",
    "            \n",
    "    def ensemble(self, method='rint'):\n",
    "        model_pred_df_list = [\n",
    "            v['cv_df'][['essay_id'] + [f'raw_score_f{i}' for i in range(len(v['models']))]]\n",
    "            for v in self.models_dict.values()\n",
    "        ]\n",
    "        \n",
    "        essay_id_df = model_pred_df_list[0]['essay_id']\n",
    "        pred_values = [np.mean(df.drop('essay_id', axis=1).values, axis=1) for df in model_pred_df_list]\n",
    "        \n",
    "        if method == 'rint':\n",
    "            pred_mean = np.rint(np.mean(pred_values, axis=0)).clip(1, 6) # take mean across all models and clip to [1, 6]\n",
    "            pred_df = pd.DataFrame(pred_mean, columns=['score'])\n",
    "            \n",
    "        elif isinstance(method, list) and len(method) == 5: # threshold\n",
    "            pred = pd.cut(np.mean(pred_values, axis=0), [-np.inf] + method + [np.inf], labels=[1, 2, 3, 4, 5, 6])\n",
    "            pred = pred.to_numpy().clip(1, 6)\n",
    "            pred_df = pd.DataFrame(pred, columns=['score'])\n",
    "            \n",
    "        else:\n",
    "            raise Exception('method is invalid')\n",
    "            \n",
    "        result = pd.concat([essay_id_df, pred_df], axis=1)\n",
    "        result['score'] = result['score'].astype(int)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    def _predict(self, conf, model, dataloader):\n",
    "        raw_predictions = []\n",
    "        \n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "\n",
    "        for inputs in dataloader:\n",
    "            inputs = collator(inputs)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                raw_outputs = model(inputs)\n",
    "            \n",
    "            outputs = self._process_outputs(conf, raw_outputs)\n",
    "            raw_predictions.append(raw_outputs.view(-1) if raw_outputs.size() == torch.Size([]) else raw_outputs)\n",
    "\n",
    "        raw_predictions = torch.cat(raw_predictions)\n",
    "\n",
    "        return raw_predictions.detach().cpu().numpy()\n",
    "    \n",
    "    def _process_outputs(self, conf, outputs):\n",
    "        if conf.num_labels == 1:\n",
    "            ouputs = outputs.squeeze()\n",
    "        else:\n",
    "            outputs = outputs.softmax(1).argmax(-1)\n",
    "        \n",
    "        if conf.criterion == 'bce':\n",
    "            outputs = outputs.sigmoid() * 5.0\n",
    "            \n",
    "        return outputs\n",
    "    \n",
    "    def _get_tokenizer(self, tokenizer_path):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        return tokenizer\n",
    "    \n",
    "    def _load_config_path(self, path, fold_num_list):\n",
    "        # /kaggle/input/fb-debertav3-roberta-large-seed0/exp54s0/best-epoch-fold3.pt\n",
    "        config_dict = {\n",
    "            'yaml': f'{path}/config.yaml',\n",
    "            'model_config': list(Path(path).glob('*_config.pt'))[0].as_posix(),\n",
    "            'tokenizer': f'{path}/tokenizers/',\n",
    "            'models': {f: f'{path}/best_score_fold{f}.pt' for f in fold_num_list},\n",
    "            'oof_df': f'{path}/oof_df.csv',\n",
    "        }\n",
    "        return config_dict\n",
    "    \n",
    "    def _load_lgbm_config_path(self, path):\n",
    "        config_dict = {\n",
    "            'models': f'{path}/models.bin',\n",
    "            'selected_feats': f'{path}/selected_feats.yaml',\n",
    "            'vectors': {\n",
    "                'tf-idf': f'{path}/tfidf_vec.bin',\n",
    "                'count': f'{path}/count_vec.bin'\n",
    "            }\n",
    "        }\n",
    "        return config_dict\n",
    "    \n",
    "    def _load_model(self, conf, model_config_path, pretrained_model_path, tokenizer):\n",
    "        model = CustomModel(conf, conf_path=model_config_path)\n",
    "        model.backbone.resize_token_embeddings(len(tokenizer))\n",
    "        state_dict = torch.load(pretrained_model_path, map_location=self.device)['model_state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        return model\n",
    "    \n",
    "    def _get_test_dataloader(self, conf, df, tokenizer, batch_num=1):\n",
    "        test_dataset = AE2Dataset(conf, df, tokenizer, output_tokens_only=True)\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=32,\n",
    "            num_workers=4,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        return test_dataloader\n",
    "        \n",
    "    def print_registered_models(self):\n",
    "        for model_name in self.models_dict.keys():\n",
    "            print(model_name)\n",
    "        for model_name in self.lgbm_models_dict.keys():\n",
    "            print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5640b2",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2024-06-15T09:40:01.899709",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.892956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8093398e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:01.914333Z",
     "iopub.status.busy": "2024-06-15T09:40:01.913977Z",
     "iopub.status.idle": "2024-06-15T09:40:07.422491Z",
     "shell.execute_reply": "2024-06-15T09:40:07.421680Z"
    },
    "papermill": {
     "duration": 5.518416,
     "end_time": "2024-06-15T09:40:07.424770",
     "exception": false,
     "start_time": "2024-06-15T09:40:01.906354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tp_df = pl.read_csv('/kaggle/input/lal-aes2-create-prompt-data/train_df_with_prompt.csv')\n",
    "# ko = tp_df.filter(pl.col('kaggle_only') == True)\n",
    "t = tp_df.with_columns(pl.col('full_text').str.split('.', inclusive=True).alias('discourse_text')).explode('discourse_text')\n",
    "t = t.with_columns(pl.col('discourse_text').str.strip_chars_end()).filter(pl.col('discourse_text') != '').filter(pl.col('discourse_text') != '.')\n",
    "\n",
    "new = []\n",
    "for name, data in t.group_by('essay_id', maintain_order=True):\n",
    "    for i in range(data.shape[0]):\n",
    "        new.append(data['essay_id'][i] + f'_{i}')\n",
    "        \n",
    "t = t.with_columns(essay_id=pl.Series(new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb243d2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:07.440133Z",
     "iopub.status.busy": "2024-06-15T09:40:07.439564Z",
     "iopub.status.idle": "2024-06-15T09:40:07.459228Z",
     "shell.execute_reply": "2024-06-15T09:40:07.458385Z"
    },
    "papermill": {
     "duration": 0.029899,
     "end_time": "2024-06-15T09:40:07.461629",
     "exception": false,
     "start_time": "2024-06-15T09:40:07.431730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (326_053, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>prompt_name</th><th>score</th><th>kaggle_only</th><th>discourse_text</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>bool</td><td>str</td></tr></thead><tbody><tr><td>&quot;000d118_0&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot;Many people ha…</td></tr><tr><td>&quot;000d118_1&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; The thing the…</td></tr><tr><td>&quot;000d118_2&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; Street parkig…</td></tr><tr><td>&quot;000d118_3&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; You probaly w…</td></tr><tr><td>&quot;000d118_4&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; The vauban pe…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;fffed3e_7&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot; if a human is…</td></tr><tr><td>&quot;fffed3e_8&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;\n",
       "\n",
       "Just like wh…</td></tr><tr><td>&quot;fffed3e_9&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;, But that onl…</td></tr><tr><td>&quot;fffed3e_10&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot; Now they are …</td></tr><tr><td>&quot;fffed3e_11&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;\n",
       "\n",
       "In Conclusio…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (326_053, 6)\n",
       "┌────────────┬──────────────────────┬─────────────────┬───────┬─────────────┬──────────────────────┐\n",
       "│ essay_id   ┆ full_text            ┆ prompt_name     ┆ score ┆ kaggle_only ┆ discourse_text       │\n",
       "│ ---        ┆ ---                  ┆ ---             ┆ ---   ┆ ---         ┆ ---                  │\n",
       "│ str        ┆ str                  ┆ str             ┆ i64   ┆ bool        ┆ str                  │\n",
       "╞════════════╪══════════════════════╪═════════════════╪═══════╪═════════════╪══════════════════════╡\n",
       "│ 000d118_0  ┆ Many people have car ┆ Car-free cities ┆ 3     ┆ false       ┆ Many people have car │\n",
       "│            ┆ where they …         ┆                 ┆       ┆             ┆ where they …         │\n",
       "│ 000d118_1  ┆ Many people have car ┆ Car-free cities ┆ 3     ┆ false       ┆ The thing they don't │\n",
       "│            ┆ where they …         ┆                 ┆       ┆             ┆ know is th…          │\n",
       "│ 000d118_2  ┆ Many people have car ┆ Car-free cities ┆ 3     ┆ false       ┆ Street parkig        │\n",
       "│            ┆ where they …         ┆                 ┆       ┆             ┆ ,driveways and ho…   │\n",
       "│ 000d118_3  ┆ Many people have car ┆ Car-free cities ┆ 3     ┆ false       ┆ You probaly won't    │\n",
       "│            ┆ where they …         ┆                 ┆       ┆             ┆ see a car in …       │\n",
       "│ 000d118_4  ┆ Many people have car ┆ Car-free cities ┆ 3     ┆ false       ┆ The vauban people    │\n",
       "│            ┆ where they …         ┆                 ┆       ┆             ┆ completed thi…       │\n",
       "│ …          ┆ …                    ┆ …               ┆ …     ┆ …           ┆ …                    │\n",
       "│ fffed3e_7  ┆ Venus is worthy      ┆ Exploring Venus ┆ 2     ┆ true        ┆ if a human is going  │\n",
       "│            ┆ place to study b…    ┆                 ┆       ┆             ┆ you need to…         │\n",
       "│ fffed3e_8  ┆ Venus is worthy      ┆ Exploring Venus ┆ 2     ┆ true        ┆                      │\n",
       "│            ┆ place to study b…    ┆                 ┆       ┆             ┆                      │\n",
       "│            ┆                      ┆                 ┆       ┆             ┆ Just like when they  │\n",
       "│            ┆                      ┆                 ┆       ┆             ┆ sent a rob…          │\n",
       "│ fffed3e_9  ┆ Venus is worthy      ┆ Exploring Venus ┆ 2     ┆ true        ┆ , But that only      │\n",
       "│            ┆ place to study b…    ┆                 ┆       ┆             ┆ lasted two weeks…    │\n",
       "│ fffed3e_10 ┆ Venus is worthy      ┆ Exploring Venus ┆ 2     ┆ true        ┆ Now they are try to  │\n",
       "│            ┆ place to study b…    ┆                 ┆       ┆             ┆ go for long…         │\n",
       "│ fffed3e_11 ┆ Venus is worthy      ┆ Exploring Venus ┆ 2     ┆ true        ┆                      │\n",
       "│            ┆ place to study b…    ┆                 ┆       ┆             ┆                      │\n",
       "│            ┆                      ┆                 ┆       ┆             ┆ In Conclusion i know │\n",
       "│            ┆                      ┆                 ┆       ┆             ┆ that tcan…           │\n",
       "└────────────┴──────────────────────┴─────────────────┴───────┴─────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39b3ff32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:07.477881Z",
     "iopub.status.busy": "2024-06-15T09:40:07.477309Z",
     "iopub.status.idle": "2024-06-15T09:40:07.645693Z",
     "shell.execute_reply": "2024-06-15T09:40:07.644675Z"
    },
    "papermill": {
     "duration": 0.178915,
     "end_time": "2024-06-15T09:40:07.647921",
     "exception": false,
     "start_time": "2024-06-15T09:40:07.469006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTERED: expD012\n"
     ]
    }
   ],
   "source": [
    "infer_models = InferModels()\n",
    "# infer_models.register('exp080', '/kaggle/input/lal-aes2-exps/exp080', [0, 1, 2, 3])\n",
    "infer_models.register('expD012', '/kaggle/input/lal-aes2-discourse/expD012', [0, 1, 2, 3])\n",
    "# infer_models.register('exp098', '/kaggle/input/lal-aes2-train', [0])\n",
    "\n",
    "\n",
    "# infermodels.register_lgbm('feats+exp015+exp022', '/kaggle/input/lal-ae2-lgbm-expnb')\n",
    "\n",
    "# infermodels.print_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c77ad58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T09:40:07.664393Z",
     "iopub.status.busy": "2024-06-15T09:40:07.663670Z",
     "iopub.status.idle": "2024-06-15T10:07:42.391786Z",
     "shell.execute_reply": "2024-06-15T10:07:42.390570Z"
    },
    "papermill": {
     "duration": 1654.739317,
     "end_time": "2024-06-15T10:07:42.394511",
     "exception": false,
     "start_time": "2024-06-15T09:40:07.655194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCING: expD012, CONFIG_EXP: D012, FOLD: 0\n",
      "INFERENCING: expD012, CONFIG_EXP: D012, FOLD: 1\n",
      "INFERENCING: expD012, CONFIG_EXP: D012, FOLD: 2\n",
      "INFERENCING: expD012, CONFIG_EXP: D012, FOLD: 3\n"
     ]
    }
   ],
   "source": [
    "infer_models.predict_cv(t.to_pandas())\n",
    "\n",
    "# pred_df = infer_models.ensemble()\n",
    "\n",
    "# if submit:\n",
    "#     display(pred_df)\n",
    "#     pred_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# lgbm_pred_df = infermodels.predict_cv_ensemble_lgbm(test_df)\n",
    "# if submit:\n",
    "#     display(lgbm_pred_df)\n",
    "#     lgbm_pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82687ce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T10:07:42.411532Z",
     "iopub.status.busy": "2024-06-15T10:07:42.411183Z",
     "iopub.status.idle": "2024-06-15T10:07:42.435525Z",
     "shell.execute_reply": "2024-06-15T10:07:42.434695Z"
    },
    "papermill": {
     "duration": 0.035294,
     "end_time": "2024-06-15T10:07:42.437731",
     "exception": false,
     "start_time": "2024-06-15T10:07:42.402437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>pred_class_0</th>\n",
       "      <th>pred_class_1</th>\n",
       "      <th>pred_class_2</th>\n",
       "      <th>pred_class_3</th>\n",
       "      <th>pred_class_4</th>\n",
       "      <th>pred_class_5</th>\n",
       "      <th>pred_class_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118_0</td>\n",
       "      <td>1.348422</td>\n",
       "      <td>-2.039210</td>\n",
       "      <td>2.770183</td>\n",
       "      <td>2.257207</td>\n",
       "      <td>-2.593693</td>\n",
       "      <td>-1.103083</td>\n",
       "      <td>-2.095595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000d118_1</td>\n",
       "      <td>-2.072755</td>\n",
       "      <td>-2.387809</td>\n",
       "      <td>0.129768</td>\n",
       "      <td>3.764541</td>\n",
       "      <td>-1.821408</td>\n",
       "      <td>-0.223503</td>\n",
       "      <td>0.909058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d118_2</td>\n",
       "      <td>-1.693010</td>\n",
       "      <td>-1.473693</td>\n",
       "      <td>1.431878</td>\n",
       "      <td>3.769820</td>\n",
       "      <td>-1.916697</td>\n",
       "      <td>-2.047137</td>\n",
       "      <td>-1.346176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000d118_3</td>\n",
       "      <td>-1.512254</td>\n",
       "      <td>-3.646935</td>\n",
       "      <td>-0.515993</td>\n",
       "      <td>6.056010</td>\n",
       "      <td>-1.528462</td>\n",
       "      <td>-1.853261</td>\n",
       "      <td>-0.455074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000d118_4</td>\n",
       "      <td>-2.831292</td>\n",
       "      <td>-1.682352</td>\n",
       "      <td>0.927727</td>\n",
       "      <td>3.703798</td>\n",
       "      <td>-1.544700</td>\n",
       "      <td>-1.427290</td>\n",
       "      <td>0.498887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326048</th>\n",
       "      <td>fffed3e_7</td>\n",
       "      <td>-3.155074</td>\n",
       "      <td>-2.279390</td>\n",
       "      <td>3.667197</td>\n",
       "      <td>3.379212</td>\n",
       "      <td>-1.769132</td>\n",
       "      <td>-2.329039</td>\n",
       "      <td>-0.179665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326049</th>\n",
       "      <td>fffed3e_8</td>\n",
       "      <td>-3.028397</td>\n",
       "      <td>-1.810841</td>\n",
       "      <td>3.698041</td>\n",
       "      <td>3.415874</td>\n",
       "      <td>-1.974055</td>\n",
       "      <td>-1.822579</td>\n",
       "      <td>-0.801626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326050</th>\n",
       "      <td>fffed3e_9</td>\n",
       "      <td>-3.198970</td>\n",
       "      <td>-1.617192</td>\n",
       "      <td>1.122726</td>\n",
       "      <td>1.032075</td>\n",
       "      <td>-1.675161</td>\n",
       "      <td>0.400315</td>\n",
       "      <td>3.448996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326051</th>\n",
       "      <td>fffed3e_10</td>\n",
       "      <td>-3.581976</td>\n",
       "      <td>-0.506038</td>\n",
       "      <td>2.807937</td>\n",
       "      <td>1.159544</td>\n",
       "      <td>-0.863772</td>\n",
       "      <td>-0.936937</td>\n",
       "      <td>1.046222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326052</th>\n",
       "      <td>fffed3e_11</td>\n",
       "      <td>-2.746639</td>\n",
       "      <td>1.406143</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>-1.035064</td>\n",
       "      <td>4.563483</td>\n",
       "      <td>-1.085738</td>\n",
       "      <td>-0.334294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326053 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          essay_id  pred_class_0  pred_class_1  pred_class_2  pred_class_3  \\\n",
       "0        000d118_0      1.348422     -2.039210      2.770183      2.257207   \n",
       "1        000d118_1     -2.072755     -2.387809      0.129768      3.764541   \n",
       "2        000d118_2     -1.693010     -1.473693      1.431878      3.769820   \n",
       "3        000d118_3     -1.512254     -3.646935     -0.515993      6.056010   \n",
       "4        000d118_4     -2.831292     -1.682352      0.927727      3.703798   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "326048   fffed3e_7     -3.155074     -2.279390      3.667197      3.379212   \n",
       "326049   fffed3e_8     -3.028397     -1.810841      3.698041      3.415874   \n",
       "326050   fffed3e_9     -3.198970     -1.617192      1.122726      1.032075   \n",
       "326051  fffed3e_10     -3.581976     -0.506038      2.807937      1.159544   \n",
       "326052  fffed3e_11     -2.746639      1.406143      0.022306     -1.035064   \n",
       "\n",
       "        pred_class_4  pred_class_5  pred_class_6  \n",
       "0          -2.593693     -1.103083     -2.095595  \n",
       "1          -1.821408     -0.223503      0.909058  \n",
       "2          -1.916697     -2.047137     -1.346176  \n",
       "3          -1.528462     -1.853261     -0.455074  \n",
       "4          -1.544700     -1.427290      0.498887  \n",
       "...              ...           ...           ...  \n",
       "326048     -1.769132     -2.329039     -0.179665  \n",
       "326049     -1.974055     -1.822579     -0.801626  \n",
       "326050     -1.675161      0.400315      3.448996  \n",
       "326051     -0.863772     -0.936937      1.046222  \n",
       "326052      4.563483     -1.085738     -0.334294  \n",
       "\n",
       "[326053 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(infer_models.models_dict['expD012']['cv_df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0258d3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T10:07:42.454349Z",
     "iopub.status.busy": "2024-06-15T10:07:42.454043Z",
     "iopub.status.idle": "2024-06-15T10:07:42.567744Z",
     "shell.execute_reply": "2024-06-15T10:07:42.566803Z"
    },
    "papermill": {
     "duration": 0.124712,
     "end_time": "2024-06-15T10:07:42.570184",
     "exception": false,
     "start_time": "2024-06-15T10:07:42.445472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (326_053, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>essay_id</th><th>full_text</th><th>prompt_name</th><th>score</th><th>kaggle_only</th><th>discourse_text</th><th>pred_class_0</th><th>pred_class_1</th><th>pred_class_2</th><th>pred_class_3</th><th>pred_class_4</th><th>pred_class_5</th><th>pred_class_6</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>bool</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;000d118_0&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot;Many people ha…</td><td>1.348422</td><td>-2.03921</td><td>2.770183</td><td>2.257207</td><td>-2.593693</td><td>-1.103083</td><td>-2.095595</td></tr><tr><td>&quot;000d118_1&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; The thing the…</td><td>-2.072755</td><td>-2.387809</td><td>0.129768</td><td>3.764541</td><td>-1.821408</td><td>-0.223503</td><td>0.909058</td></tr><tr><td>&quot;000d118_2&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; Street parkig…</td><td>-1.69301</td><td>-1.473693</td><td>1.431878</td><td>3.76982</td><td>-1.916697</td><td>-2.047137</td><td>-1.346176</td></tr><tr><td>&quot;000d118_3&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; You probaly w…</td><td>-1.512254</td><td>-3.646935</td><td>-0.515993</td><td>6.05601</td><td>-1.528462</td><td>-1.853261</td><td>-0.455074</td></tr><tr><td>&quot;000d118_4&quot;</td><td>&quot;Many people ha…</td><td>&quot;Car-free citie…</td><td>3</td><td>false</td><td>&quot; The vauban pe…</td><td>-2.831292</td><td>-1.682352</td><td>0.927727</td><td>3.703798</td><td>-1.5447</td><td>-1.42729</td><td>0.498887</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;fffed3e_7&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot; if a human is…</td><td>-3.155074</td><td>-2.27939</td><td>3.667197</td><td>3.379212</td><td>-1.769132</td><td>-2.329039</td><td>-0.179665</td></tr><tr><td>&quot;fffed3e_8&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;\n",
       "\n",
       "Just like wh…</td><td>-3.028397</td><td>-1.810841</td><td>3.698041</td><td>3.415874</td><td>-1.974055</td><td>-1.822579</td><td>-0.801626</td></tr><tr><td>&quot;fffed3e_9&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;, But that onl…</td><td>-3.19897</td><td>-1.617192</td><td>1.122726</td><td>1.032075</td><td>-1.675161</td><td>0.400315</td><td>3.448996</td></tr><tr><td>&quot;fffed3e_10&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot; Now they are …</td><td>-3.581976</td><td>-0.506038</td><td>2.807937</td><td>1.159544</td><td>-0.863772</td><td>-0.936937</td><td>1.046222</td></tr><tr><td>&quot;fffed3e_11&quot;</td><td>&quot;Venus is worth…</td><td>&quot;Exploring Venu…</td><td>2</td><td>true</td><td>&quot;\n",
       "\n",
       "In Conclusio…</td><td>-2.746639</td><td>1.406143</td><td>0.022306</td><td>-1.035064</td><td>4.563483</td><td>-1.085738</td><td>-0.334294</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (326_053, 13)\n",
       "┌────────────┬────────────┬────────────┬───────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ essay_id   ┆ full_text  ┆ prompt_nam ┆ score ┆ … ┆ pred_clas ┆ pred_clas ┆ pred_clas ┆ pred_clas │\n",
       "│ ---        ┆ ---        ┆ e          ┆ ---   ┆   ┆ s_3       ┆ s_4       ┆ s_5       ┆ s_6       │\n",
       "│ str        ┆ str        ┆ ---        ┆ i64   ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆ str        ┆       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ f32       │\n",
       "╞════════════╪════════════╪════════════╪═══════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 000d118_0  ┆ Many       ┆ Car-free   ┆ 3     ┆ … ┆ 2.257207  ┆ -2.593693 ┆ -1.103083 ┆ -2.095595 │\n",
       "│            ┆ people     ┆ cities     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ have car   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ where they ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000d118_1  ┆ Many       ┆ Car-free   ┆ 3     ┆ … ┆ 3.764541  ┆ -1.821408 ┆ -0.223503 ┆ 0.909058  │\n",
       "│            ┆ people     ┆ cities     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ have car   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ where they ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000d118_2  ┆ Many       ┆ Car-free   ┆ 3     ┆ … ┆ 3.76982   ┆ -1.916697 ┆ -2.047137 ┆ -1.346176 │\n",
       "│            ┆ people     ┆ cities     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ have car   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ where they ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000d118_3  ┆ Many       ┆ Car-free   ┆ 3     ┆ … ┆ 6.05601   ┆ -1.528462 ┆ -1.853261 ┆ -0.455074 │\n",
       "│            ┆ people     ┆ cities     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ have car   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ where they ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 000d118_4  ┆ Many       ┆ Car-free   ┆ 3     ┆ … ┆ 3.703798  ┆ -1.5447   ┆ -1.42729  ┆ 0.498887  │\n",
       "│            ┆ people     ┆ cities     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ have car   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ where they ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …     ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ fffed3e_7  ┆ Venus is   ┆ Exploring  ┆ 2     ┆ … ┆ 3.379212  ┆ -1.769132 ┆ -2.329039 ┆ -0.179665 │\n",
       "│            ┆ worthy     ┆ Venus      ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ place to   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ study b…   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ fffed3e_8  ┆ Venus is   ┆ Exploring  ┆ 2     ┆ … ┆ 3.415874  ┆ -1.974055 ┆ -1.822579 ┆ -0.801626 │\n",
       "│            ┆ worthy     ┆ Venus      ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ place to   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ study b…   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ fffed3e_9  ┆ Venus is   ┆ Exploring  ┆ 2     ┆ … ┆ 1.032075  ┆ -1.675161 ┆ 0.400315  ┆ 3.448996  │\n",
       "│            ┆ worthy     ┆ Venus      ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ place to   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ study b…   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ fffed3e_10 ┆ Venus is   ┆ Exploring  ┆ 2     ┆ … ┆ 1.159544  ┆ -0.863772 ┆ -0.936937 ┆ 1.046222  │\n",
       "│            ┆ worthy     ┆ Venus      ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ place to   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ study b…   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ fffed3e_11 ┆ Venus is   ┆ Exploring  ┆ 2     ┆ … ┆ -1.035064 ┆ 4.563483  ┆ -1.085738 ┆ -0.334294 │\n",
       "│            ┆ worthy     ┆ Venus      ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ place to   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│            ┆ study b…   ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = t.join(pl.from_pandas(infer_models.models_dict['expD012']['cv_df']), on='essay_id')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc627f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T10:07:42.588050Z",
     "iopub.status.busy": "2024-06-15T10:07:42.587756Z",
     "iopub.status.idle": "2024-06-15T10:07:43.593398Z",
     "shell.execute_reply": "2024-06-15T10:07:43.592393Z"
    },
    "papermill": {
     "duration": 1.0171,
     "end_time": "2024-06-15T10:07:43.595774",
     "exception": false,
     "start_time": "2024-06-15T10:07:42.578674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result.write_csv('all_dt_pred.csv')\n",
    "result.write_parquet('all_dt_pred.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3700e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T10:07:43.613621Z",
     "iopub.status.busy": "2024-06-15T10:07:43.613322Z",
     "iopub.status.idle": "2024-06-15T10:07:43.617149Z",
     "shell.execute_reply": "2024-06-15T10:07:43.616295Z"
    },
    "papermill": {
     "duration": 0.015042,
     "end_time": "2024-06-15T10:07:43.619123",
     "exception": false,
     "start_time": "2024-06-15T10:07:43.604081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# infer_models.models_dict['expD002']['cv_df'].to_csv('dt_pred.csv', index=False)\n",
    "# t.write_csv('ko_sen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48de7f85",
   "metadata": {
    "papermill": {
     "duration": 0.00784,
     "end_time": "2024-06-15T10:07:43.635128",
     "exception": false,
     "start_time": "2024-06-15T10:07:43.627288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4902589,
     "sourceId": 8567314,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5075729,
     "sourceId": 8622787,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4977617,
     "sourceId": 8693767,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5143296,
     "sourceId": 8597191,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 177401657,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 181500981,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 182216879,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 183012865,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1689.022645,
   "end_time": "2024-06-15T10:07:46.424032",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-15T09:39:37.401387",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
