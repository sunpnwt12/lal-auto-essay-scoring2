{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d702c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:45:56.947267Z",
     "iopub.status.busy": "2024-06-30T04:45:56.946859Z",
     "iopub.status.idle": "2024-06-30T04:46:10.456849Z",
     "shell.execute_reply": "2024-06-30T04:46:10.455916Z"
    },
    "papermill": {
     "duration": 13.522883,
     "end_time": "2024-06-30T04:46:10.459251",
     "exception": false,
     "start_time": "2024-06-30T04:45:56.936368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/lal-aes2-wheels/iterative_stratification-0.1.7-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from iterative-stratification==0.1.7) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification==0.1.7) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->iterative-stratification==0.1.7) (3.2.0)\r\n",
      "Installing collected packages: iterative-stratification\r\n",
      "Successfully installed iterative-stratification-0.1.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install '/kaggle/input/lal-aes2-wheels/iterative_stratification-0.1.7-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433d87ec",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:10.478533Z",
     "iopub.status.busy": "2024-06-30T04:46:10.478213Z",
     "iopub.status.idle": "2024-06-30T04:46:28.887050Z",
     "shell.execute_reply": "2024-06-30T04:46:28.885977Z"
    },
    "papermill": {
     "duration": 18.421176,
     "end_time": "2024-06-30T04:46:28.889228",
     "exception": false,
     "start_time": "2024-06-30T04:46:10.468052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 04:46:20.460487: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-30 04:46:20.460604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-30 04:46:20.588761: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "torch version: 2.1.2\n",
      "transfromers version: 4.38.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding\n",
    "from tokenizers import AddedToken\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, GroupKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "print(f'python version: {sys.version}') \n",
    "print(f'torch version: {torch.__version__}')\n",
    "print(f'transfromers version: {transformers.__version__}')\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter('ignore')\n",
    "transformers.utils.logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255b09b",
   "metadata": {
    "papermill": {
     "duration": 0.00835,
     "end_time": "2024-06-30T04:46:28.906591",
     "exception": false,
     "start_time": "2024-06-30T04:46:28.898241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e988f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:28.925654Z",
     "iopub.status.busy": "2024-06-30T04:46:28.925056Z",
     "iopub.status.idle": "2024-06-30T04:46:28.930974Z",
     "shell.execute_reply": "2024-06-30T04:46:28.930098Z"
    },
    "papermill": {
     "duration": 0.017774,
     "end_time": "2024-06-30T04:46:28.932968",
     "exception": false,
     "start_time": "2024-06-30T04:46:28.915194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38b6e6",
   "metadata": {
    "papermill": {
     "duration": 0.008276,
     "end_time": "2024-06-30T04:46:28.950094",
     "exception": false,
     "start_time": "2024-06-30T04:46:28.941818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48473c77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:28.969968Z",
     "iopub.status.busy": "2024-06-30T04:46:28.969615Z",
     "iopub.status.idle": "2024-06-30T04:46:28.976183Z",
     "shell.execute_reply": "2024-06-30T04:46:28.975216Z"
    },
    "papermill": {
     "duration": 0.018226,
     "end_time": "2024-06-30T04:46:28.978326",
     "exception": false,
     "start_time": "2024-06-30T04:46:28.960100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df_):\n",
    "    df = df_.copy()\n",
    "    \n",
    "    drop_id_list = ['e9be80d', '6017fea']\n",
    "    \n",
    "    df = df[~df['essay_id'].isin(drop_id_list)].reset_index(drop=True)\n",
    "\n",
    "    df['label'] = df['score'].copy() - 1\n",
    "    df['tokened_text'] = df['tokened_text'].str.replace('\\xa0', ' ')\n",
    "    df['tokened_text'] = df['tokened_text'].str.replace('\\n\\n', '[PARAGRAPH]')\n",
    "    df['tokened_text'] = df['tokened_text'].str.strip()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10236bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:28.997692Z",
     "iopub.status.busy": "2024-06-30T04:46:28.997003Z",
     "iopub.status.idle": "2024-06-30T04:46:29.010097Z",
     "shell.execute_reply": "2024-06-30T04:46:29.009192Z"
    },
    "papermill": {
     "duration": 0.025199,
     "end_time": "2024-06-30T04:46:29.012154",
     "exception": false,
     "start_time": "2024-06-30T04:46:28.986955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_fold(conf, df_):\n",
    "    df = df_.copy(deep=True)\n",
    "    \n",
    "    df[\"fold\"] = -1\n",
    "    X = df['tokened_text']\n",
    "    y = df['label']\n",
    "    \n",
    "    if conf.cv_strat == 'stratified_kfold':\n",
    "        skf = StratifiedKFold(n_splits=conf.num_folds, shuffle=True, random_state=conf.seed)\n",
    "        for fold, (_, valid_idx) in enumerate(skf.split(X, y)):\n",
    "            df.loc[valid_idx, 'fold'] = fold\n",
    "            \n",
    "    elif conf.cv_strat == 'stratified_group_kfold' and 'prompt_name' in df.columns:\n",
    "        g = df['prompt_name']\n",
    "        sgkf = StratifiedGroupKFold(n_splits=conf.num_folds, shuffle=True, random_state=conf.seed)\n",
    "        for fold, (_, valid_idx) in enumerate(sgkf.split(X, y, g)):\n",
    "            df.loc[valid_idx, 'fold'] = fold\n",
    "        \n",
    "    elif conf.cv_strat == 'group_kfold' and 'prompt_name' in df.columns:\n",
    "        g = df['prompt_name']\n",
    "        sgkf = GroupKFold(n_splits=conf.num_folds)\n",
    "        for fold, (_, valid_idx) in enumerate(sgkf.split(X, y, g)):\n",
    "            df.loc[valid_idx, 'fold'] = fold\n",
    "            \n",
    "    elif conf.cv_strat == 'multilabel_stratified_kfold' and 'prompt_name' in df.columns:\n",
    "        target_cols = ['prompt_name', 'score']\n",
    "        labels_map = {\n",
    "            0: 'Car-free cities',\n",
    "            1: '\"A Cowboy Who Rode the Waves\"',\n",
    "            2: 'Exploring Venus',\n",
    "            3: 'Facial action coding system',\n",
    "            4: 'The Face on Mars',\n",
    "            5: 'Driverless cars',\n",
    "            6: 'Does the electoral college work?'\n",
    "        }\n",
    "        rev_labels_map = {v: k for k, v in labels_map.items()}\n",
    "        df['prompt_name'] = df['prompt_name'].replace(rev_labels_map).astype(int)\n",
    "        y = pd.get_dummies(data=df[target_cols], columns=target_cols, dtype=int)\n",
    "        \n",
    "        mskf = MultilabelStratifiedKFold(n_splits=conf.num_folds, shuffle=True, random_state=conf.seed)\n",
    "        for fold, (_, valid_idx) in enumerate(mskf.split(X, y)):\n",
    "            df.loc[valid_idx, 'fold'] = fold\n",
    "        \n",
    "    df['fold'] = df['fold'].astype(int)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85015b1f",
   "metadata": {
    "papermill": {
     "duration": 0.008714,
     "end_time": "2024-06-30T04:46:29.030075",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.021361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8edb72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.049783Z",
     "iopub.status.busy": "2024-06-30T04:46:29.049450Z",
     "iopub.status.idle": "2024-06-30T04:46:29.061138Z",
     "shell.execute_reply": "2024-06-30T04:46:29.060238Z"
    },
    "papermill": {
     "duration": 0.023782,
     "end_time": "2024-06-30T04:46:29.063316",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.039534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AE2Dataset(Dataset):\n",
    "    def __init__(self, conf, df, tokenizer, output_tokens_only=False):\n",
    "        self.conf = conf\n",
    "\n",
    "        self.full_texts = df[self.conf.train_col].reset_index(drop=True).values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_tokens_only = output_tokens_only\n",
    "        \n",
    "        if not self.output_tokens_only:\n",
    "            self.essay_ids = df['essay_id'].reset_index(drop=True).values\n",
    "            self.labels = df[self.conf.target_col].reset_index(drop=True).values\n",
    "            if self.conf.num_labels == 1: # regression\n",
    "                self.label_dtype = torch.float\n",
    "                if self.conf.criterion == 'bce':\n",
    "                    self.labels = self.labels / 5.0 \n",
    "            else: # classication\n",
    "                self.label_dtype = torch.long\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.full_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self._get_token(idx)\n",
    "        if self.output_tokens_only:\n",
    "            return tokens\n",
    "        else:\n",
    "            ids = self.essay_ids[idx]\n",
    "            labels = self._get_label(idx)\n",
    "        return {'tokens': tokens, 'labels': labels, 'ids': ids}\n",
    "    \n",
    "    def _get_token(self, idx):\n",
    "        tokenized = self.tokenizer(\n",
    "            self.full_texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.conf.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        \n",
    "        return {k: torch.tensor(v, dtype=torch.long) for k, v in tokenized.items()}\n",
    "    \n",
    "    def _get_label(self, idx):\n",
    "        return torch.tensor(self.labels[idx], dtype=self.label_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85185d78",
   "metadata": {
    "papermill": {
     "duration": 0.008823,
     "end_time": "2024-06-30T04:46:29.080934",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.072111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2b2531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.099859Z",
     "iopub.status.busy": "2024-06-30T04:46:29.099527Z",
     "iopub.status.idle": "2024-06-30T04:46:29.123513Z",
     "shell.execute_reply": "2024-06-30T04:46:29.122639Z"
    },
    "papermill": {
     "duration": 0.03587,
     "end_time": "2024-06-30T04:46:29.125397",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.089527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "class ConcatPooling(nn.Module):\n",
    "    def __init__(self, pooling_last=4):\n",
    "        super().__init__()\n",
    "        self.pooling_last = pooling_last\n",
    "        \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        concat_pooling = torch.cat(tuple(all_hidden_states[-l] for l in range(1, self.pooling_last + 1)), -1)\n",
    "        concat_pooling = concat_pooling[:, 0] # select the first one\n",
    "        return concat_pooling\n",
    "    \n",
    "# https://www.kaggle.com/competitions/google-quest-challenge/discussion/129840    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float)\n",
    "            )\n",
    "\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average[:, 0]\n",
    "    \n",
    "# https://www.kaggle.com/code/rhtsingh/utilizing-transformer-representations-efficiently\n",
    "class LSTMPooling(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size, hiddendim_lstm):\n",
    "        super().__init__()\n",
    "        self.num_hidden_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hiddendim_lstm = hiddendim_lstm\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        all_hidden_states = torch.stack(backbone_outputs['hidden_states'])\n",
    "        #\n",
    "        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n",
    "                                     for layer_i in range(1, self.num_hidden_layers+1)], dim=-1)\n",
    "        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n",
    "        out, _ = self.lstm(hidden_states, None)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "class GeMPooling(nn.Module):\n",
    "    def __init__(self, dim=1, cfg=None, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "        self.feat_mult = 1\n",
    "        # x seeems last hidden state\n",
    "\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.shape)\n",
    "        last_hidden_state = (last_hidden_state.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n",
    "        ret = last_hidden_state / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n",
    "        ret = ret.pow(1 / self.p)\n",
    "        return ret\n",
    "    \n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hiddendim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hiddendim, hiddendim),\n",
    "            nn.LayerNorm(hiddendim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hiddendim, 1),\n",
    "        )\n",
    "    def forward(self, backbone_outputs, inputs):\n",
    "        # modified for cleaner code\n",
    "        last_hidden_state = backbone_outputs['last_hidden_state']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        #\n",
    "        w = self.attention(last_hidden_state).float()\n",
    "        w[attention_mask==0]=float('-inf')\n",
    "        w = torch.softmax(w,1)\n",
    "        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n",
    "        return attention_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462b75fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.144156Z",
     "iopub.status.busy": "2024-06-30T04:46:29.143844Z",
     "iopub.status.idle": "2024-06-30T04:46:29.163924Z",
     "shell.execute_reply": "2024-06-30T04:46:29.163151Z"
    },
    "papermill": {
     "duration": 0.031912,
     "end_time": "2024-06-30T04:46:29.165970",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.134058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, conf, conf_path=None):\n",
    "        super().__init__()\n",
    "        self.conf_path = conf_path\n",
    "        self.multi_dropout = conf.multi_dropout\n",
    "        if not self.conf_path:\n",
    "            self.model_conf = AutoConfig.from_pretrained(conf.model_name, output_hidden_states=True)\n",
    "            self.model_conf = self._set_dropout(self.model_conf)\n",
    "            self.backbone = AutoModel.from_pretrained(conf.model_name, config=self.model_conf)\n",
    "        else:\n",
    "            self.model_conf = torch.load(self.conf_path)\n",
    "            self.backbone = AutoModel.from_config(self.model_conf)\n",
    "        \n",
    "        if conf.gradient_checkpointing:\n",
    "            self.backbone.gradient_checkpointing_enable()\n",
    "            \n",
    "        if conf.freeze_embeddings:\n",
    "            self._freeze(self.backbone.embeddings)\n",
    "            \n",
    "        if conf.freeze_n_layers > 0:\n",
    "            self._freeze(self.backbone.encoder.layer[: conf.freeze_n_layers])\n",
    "        \n",
    "        self.pooler, hidden_size = self.get_pooling_layer(conf)\n",
    "        self.fc = nn.Linear(hidden_size, conf.num_labels)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        if self.multi_dropout and conf.num_labels > 1:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "    \n",
    "    def _set_dropout(self, model_conf, ratio=0.):\n",
    "        model_conf.attention_dropout = ratio\n",
    "        model_conf.attention_probs_dropout_prob = ratio\n",
    "        model_conf.hidden_dropout = ratio\n",
    "        model_conf.hidden_dropout_prob = ratio\n",
    "        \n",
    "        return model_conf\n",
    "    \n",
    "    def _freeze(self, module):\n",
    "        for parameter in module.parameters():\n",
    "            parameter.require_grad = False\n",
    "    \n",
    "    def get_pooling_layer(self, conf):\n",
    "        if conf.pooling_layer == 'mean_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return MeanPooling(), hidden_size\n",
    "        if conf.pooling_layer == 'concat_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size * conf.ccp_pooling_last\n",
    "            return ConcatPooling(conf.ccp_pooling_last), hidden_size\n",
    "        if conf.pooling_layer == 'weighted_layer_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return WeightedLayerPooling(self.model_conf.num_hidden_layers, conf.wlp_layer_start), hidden_size\n",
    "        if conf.pooling_layer == 'lstm_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return LSTMPooling(self.model_conf.num_hidden_layers, hidden_size, conf.lstm_hidden), hidden_size\n",
    "        if conf.pooling_layer == 'gem_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return GeMPooling(), hidden_size\n",
    "        if conf.pooling_layer == 'attention_pooling':\n",
    "            hidden_size = self.model_conf.hidden_size\n",
    "            return AttentionPooling(hidden_size), hidden_size\n",
    "        else:\n",
    "            raise Exception('Invalid pooling layer name')\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.model_conf.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        backbone_outputs = self.backbone(**inputs)\n",
    "        pooler_outputs = self.pooler(backbone_outputs, inputs)\n",
    "        if self.multi_dropout:\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    h = self.fc(dropout(pooler_outputs))\n",
    "                else:\n",
    "                    h += self.fc(dropout(pooler_outputs))\n",
    "\n",
    "            outputs = h / len(self.dropouts)\n",
    "        else:\n",
    "            outputs = self.fc(pooler_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ed129",
   "metadata": {
    "papermill": {
     "duration": 0.008555,
     "end_time": "2024-06-30T04:46:29.183374",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.174819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7d9638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.202657Z",
     "iopub.status.busy": "2024-06-30T04:46:29.202316Z",
     "iopub.status.idle": "2024-06-30T04:46:29.209563Z",
     "shell.execute_reply": "2024-06-30T04:46:29.208627Z"
    },
    "papermill": {
     "duration": 0.0195,
     "end_time": "2024-06-30T04:46:29.211579",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.192079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
    "class Averager:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "    def get_average(self):\n",
    "        return self.avg\n",
    "    \n",
    "    def get_value(self):\n",
    "        return self.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4bfb52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.230571Z",
     "iopub.status.busy": "2024-06-30T04:46:29.230234Z",
     "iopub.status.idle": "2024-06-30T04:46:29.239537Z",
     "shell.execute_reply": "2024-06-30T04:46:29.238693Z"
    },
    "papermill": {
     "duration": 0.021148,
     "end_time": "2024-06-30T04:46:29.241514",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.220366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimerError(Exception):\n",
    "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.split_time = []\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start a new timer\"\"\"\n",
    "        if self._start_time is not None:\n",
    "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
    "\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        self._start_time = None\n",
    "    \n",
    "    def get_time(self):\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        return time.perf_counter() - self._start_time\n",
    "    \n",
    "    def split(self):\n",
    "        if self._start_time is None:\n",
    "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
    "            \n",
    "        self.split_time.append(time.perf_counter() - self._start_time)\n",
    "    \n",
    "    def get_split_time(self, idx):\n",
    "        return self.split_time[idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def formatting(second):\n",
    "        return str(datetime.timedelta(seconds=round(second)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790acd4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.260554Z",
     "iopub.status.busy": "2024-06-30T04:46:29.260276Z",
     "iopub.status.idle": "2024-06-30T04:46:29.295703Z",
     "shell.execute_reply": "2024-06-30T04:46:29.294893Z"
    },
    "papermill": {
     "duration": 0.047663,
     "end_time": "2024-06-30T04:46:29.297739",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.250076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_config(class_obj):\n",
    "    config_dict = {}\n",
    "    for k, v in zip(class_obj.__dict__.keys(), class_obj.__dict__.values()):\n",
    "        if not k[0].startswith('_'):\n",
    "            config_dict[k] = v\n",
    "\n",
    "    with open(class_obj.save_path + 'config.yaml', 'w+') as file:\n",
    "        yaml.dump(config_dict, file)\n",
    "\n",
    "    print('Extracted config')\n",
    "\n",
    "def get_tokenizer(conf):\n",
    "    addition_tokens = [\n",
    "        '[UNANNOTATED]',\n",
    "        '[LEAD]',\n",
    "        '[POSITION]',\n",
    "        '[CLAIM]',\n",
    "        '[EVIDENCE]',\n",
    "        '[CONCLUDE]',\n",
    "        '[COUNTER]',\n",
    "        '[REBUTTAL]',\n",
    "    ] # not using this anymore, but left it right here\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(conf.model_name)\n",
    "#     tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': ['[PARAGRAPH]'] + addition_tokens})\n",
    "    tokenizer_file = Path(conf.save_path, 'tokenizers/')\n",
    "\n",
    "    if not tokenizer_file.is_file():\n",
    "        tokenizer.save_pretrained(tokenizer_file) # save tokenizer for later infer\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "# optimize padding size\n",
    "# https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train/notebook\n",
    "def collator(inputs):\n",
    "    mask_len = int(inputs['attention_mask'].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs\n",
    "\n",
    "def get_dataloader(conf, df, tokenizer, fold_num):\n",
    "    \n",
    "    training_set = df[df['fold'] != fold_num]\n",
    "    validating_set = df[df['fold'] == fold_num]\n",
    "\n",
    "    train_dataset = AE2Dataset(conf, training_set, tokenizer, output_tokens_only=False)\n",
    "    valid_dataset = AE2Dataset(conf, validating_set, tokenizer, output_tokens_only=False)\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=conf.batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=conf.batch_size,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, valid_dataloader\n",
    "\n",
    "def get_model(conf):\n",
    "    model = CustomModel(conf)\n",
    "    model_config_file = Path(conf.save_path, Path(conf.model_name).name + '_config.pt')\n",
    "    \n",
    "    if not model_config_file.is_file():\n",
    "        torch.save(model.model_conf, model_config_file)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def load_model(conf, fold_num, device, model_path):\n",
    "    model_config_path = list(Path(model_path).glob('*_config.pt'))[0].as_posix()\n",
    "    pretrained_model_path = f'{model_path}/best_score_fold{fold_num}.pt'\n",
    "\n",
    "    model = CustomModel(conf, conf_path=model_config_path)\n",
    "    model_config_file = Path(conf.save_path, Path(conf.model_name).name + '_config.pt')\n",
    "\n",
    "    if not model_config_file.is_file():\n",
    "        torch.save(model.model_conf, model_config_file)\n",
    "    state_dict = torch.load(pretrained_model_path, map_location=device)['model_state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f'Pretrained Model Fold {fold_num} Loaded')\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_optimizer(conf):\n",
    "    optimizer_dict = {\n",
    "        'adamw' : optim.AdamW,\n",
    "    }\n",
    "    \n",
    "    return optimizer_dict[conf.optimizer]\n",
    "\n",
    "def get_optimizer_grouped_params(conf, model):\n",
    "    layerwise_lr_decay = conf.layerwise_lr_decay\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    # initialize lr for task specific layer\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": conf.decoder_lr,\n",
    "        },\n",
    "    ]\n",
    "    # initialize lr for extra params in encoder\n",
    "    extra_params = [\n",
    "        (n, p)\n",
    "        for n, p in model.named_parameters()\n",
    "        if \"backbone\" in n\n",
    "        and \"backbone.embeddings\" not in n\n",
    "        and \"backbone.encoder.layer\" not in n\n",
    "    ]\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in extra_params if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": conf.weight_decay,\n",
    "            \"lr\": conf.encoder_lr,\n",
    "        },\n",
    "    ]\n",
    "    optimizer_grouped_parameters += [\n",
    "        {\n",
    "            \"params\": [p for n, p in extra_params if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "            \"lr\": conf.encoder_lr,\n",
    "        },\n",
    "    ]\n",
    "    # initialize lrs for every layer\n",
    "    layers = [model.backbone.embeddings] + list(model.backbone.encoder.layer)\n",
    "    layers.reverse()\n",
    "    lr = conf.decoder_lr\n",
    "    for layer in layers:\n",
    "        optimizer_grouped_parameters += [\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": conf.weight_decay,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "                \"lr\": lr,\n",
    "            },\n",
    "        ]\n",
    "        lr *= layerwise_lr_decay\n",
    "    return optimizer_grouped_parameters\n",
    "\n",
    "def get_optimizer_params(conf, model, weight_decay=0.0):\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.backbone.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         'lr': conf.encoder_lr, 'weight_decay': conf.weight_decay},\n",
    "        {'params': [p for n, p in model.backbone.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "         'lr': conf.encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"backbone\" not in n],\n",
    "         'lr': conf.decoder_lr, 'weight_decay': 0.0},\n",
    "    ]\n",
    "    return optimizer_parameters\n",
    "\n",
    "\n",
    "def get_scheduler(conf, samples_per_epoch):\n",
    "    scheduler_dict = {\n",
    "        'cosine_warmup': {\n",
    "            'scheduler': transformers.get_cosine_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "                'num_training_steps': samples_per_epoch * conf.num_epochs,\n",
    "            }\n",
    "        },\n",
    "        'linear_warmup': {\n",
    "            'scheduler':transformers.get_linear_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "                'num_training_steps': samples_per_epoch * conf.num_epochs,\n",
    "            }\n",
    "        },\n",
    "        'poly_warmup': {\n",
    "            'scheduler':transformers.get_polynomial_decay_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "                'num_training_steps': samples_per_epoch * conf.num_epochs,\n",
    "                'power': conf.poly_power\n",
    "            }\n",
    "        },\n",
    "        'constant_warmup': {\n",
    "            'scheduler':transformers.get_constant_schedule_with_warmup,\n",
    "            'hparams': {\n",
    "                'num_warmup_steps': int(samples_per_epoch * conf.num_epochs * conf.warmup_ratios),\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    return scheduler_dict[conf.scheduler]['scheduler'], scheduler_dict[conf.scheduler]['hparams']\n",
    "    \n",
    "def get_criterion(conf):\n",
    "    criterion_dict = {\n",
    "        'ce': nn.CrossEntropyLoss(), # classification\n",
    "        'bce': nn.BCEWithLogitsLoss(), # reg as cls\n",
    "        'mse': nn.MSELoss(), # regression\n",
    "        'huber': nn.HuberLoss(),\n",
    "    }\n",
    "    return criterion_dict[conf.criterion]\n",
    "\n",
    "def process_outputs(y_trues, y_preds, loss_fn):\n",
    "    \n",
    "    if loss_fn == 'mse' or loss_fn == 'huber':\n",
    "        y_preds = y_preds.detach().cpu().numpy()\n",
    "        y_preds = np.rint(y_preds.reshape(-1)).astype(int)\n",
    "        y_trues = y_trues.detach().cpu().numpy()\n",
    "        \n",
    "    elif loss_fn == 'ce':\n",
    "        y_preds = y_preds.detach().cpu().numpy().argmax(-1)\n",
    "        y_trues = y_trues.detach().cpu().numpy()\n",
    "        \n",
    "    elif loss_fn == 'bce':\n",
    "        y_preds = y_preds.sigmoid().detach().cpu().numpy()\n",
    "        y_trues = y_trues.detach().cpu().numpy()\n",
    "        y_preds = np.rint(y_preds * 5.0).astype(int) # scaled back\n",
    "        y_trues = np.rint(y_trues * 5.0).astype(int) # scaled back\n",
    "        \n",
    "    else:\n",
    "        raise Exception('loss_fn is invalid')\n",
    "        \n",
    "    return y_trues, y_preds\n",
    "\n",
    "def calculate_qwk_score(y_trues, y_preds):\n",
    "    qwk = cohen_kappa_score(y_trues, y_preds, weights='quadratic')\n",
    "    return qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7115f51",
   "metadata": {
    "papermill": {
     "duration": 0.008535,
     "end_time": "2024-06-30T04:46:29.314962",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.306427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2737c1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.335502Z",
     "iopub.status.busy": "2024-06-30T04:46:29.334623Z",
     "iopub.status.idle": "2024-06-30T04:46:29.371257Z",
     "shell.execute_reply": "2024-06-30T04:46:29.370506Z"
    },
    "papermill": {
     "duration": 0.049167,
     "end_time": "2024-06-30T04:46:29.373330",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.324163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, debug_run, fold, conf, device, model, optimizer, optim_params, scheduler, scheduler_hparams, criterion):\n",
    "        self.debug_run = debug_run\n",
    "        self.current_fold = fold\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer(optim_params, lr=conf.encoder_lr, eps=conf.optim_eps, betas=(conf.optim_betas1, conf.optim_betas2))\n",
    "        self.scheduler = scheduler(self.optimizer, **scheduler_hparams)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.save_path = conf.save_path\n",
    "        self.num_epochs = conf.num_epochs\n",
    "        self.verbose_step = conf.verbose_step\n",
    "        self.apex = conf.apex\n",
    "        self.clip_grad_norm = conf.clip_grad_norm\n",
    "        self.max_grad_norm = conf.max_grad_norm\n",
    "        self.criterion_name = conf.criterion\n",
    "        self.num_labels = conf.num_labels\n",
    "        self.exp_num = conf.exp\n",
    "\n",
    "        self.scaler = GradScaler(enabled=self.apex)\n",
    "\n",
    "        self.best_train_loss = torch.tensor(10000)\n",
    "        self.best_valid_loss = torch.tensor(10000)\n",
    "        self.best_qwk_score = -np.inf\n",
    "        \n",
    "        self.best_fold_y_preds = np.array([])\n",
    "        self.best_fold_y_preds_raw = torch.tensor([])\n",
    "        \n",
    "        self.record_df_columns = ['fold', 'epoch', 'train_loss', 'valid_loss', 'qwk_score']\n",
    "        self.record_df = pd.DataFrame(columns=self.record_df_columns)\n",
    "\n",
    "        \n",
    "    def fit(self, train_loader, valid_loader):\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.log(f'exp: {self.exp_num}')\n",
    "        self.log(f'--- FOLD {self.current_fold} ---')\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.current_epoch = epoch\n",
    "            \n",
    "            train_loss = self._train_fn(train_loader)\n",
    "            valid_loss, ids, y_trues, raw_y_preds = self._valid_fn(valid_loader)\n",
    "            \n",
    "            y_trues, y_preds = process_outputs(y_trues, raw_y_preds, self.criterion_name)\n",
    "            \n",
    "            qwk_score = calculate_qwk_score(y_trues, y_preds)\n",
    "            \n",
    "            self._compare_and_save(qwk_score, train_loss, valid_loss, y_preds, raw_y_preds.detach().cpu())\n",
    "            self._record([self.current_fold, self.current_epoch, train_loss, valid_loss, qwk_score])\n",
    "\n",
    "            self.log(f'-- [Fold: {self.current_fold}, Epoch: {self.current_epoch + 1}] DONE --\\n')\n",
    "\n",
    "        folds_preds_dict = {}\n",
    "        folds_preds_dict['essay_id'] = ids\n",
    "        if  self.criterion_name == 'ce':\n",
    "            softmaxed = self.best_fold_y_preds_raw.softmax(1).numpy()\n",
    "            for c in range(self.num_labels):\n",
    "                folds_preds_dict[f'pred_p_{c}'] = softmaxed[:, c]\n",
    "            for c in range(self.num_labels):\n",
    "                folds_preds_dict[f'raw_pred_p_{c}'] = self.best_fold_y_preds_raw[:, c].numpy()\n",
    "            folds_preds_dict['pred_c'] = self.best_fold_y_preds + 1\n",
    "        else:\n",
    "            folds_preds_dict['score'] = self.best_fold_y_preds + 1\n",
    "            folds_preds_dict['raw_score'] = self.best_fold_y_preds_raw.numpy() + 1\n",
    "    \n",
    "        fold_preds = pd.DataFrame(folds_preds_dict)\n",
    "        \n",
    "        return self.record_df, fold_preds\n",
    "    \n",
    "    def _train_fn(self, train_loader):\n",
    "        self.log('TRAINL_LOOP')\n",
    "        self.model.train()\n",
    "        total_loss = Averager()\n",
    "        current_lr = self.scheduler.get_lr()[0]\n",
    "        timer = Timer()\n",
    "        timer.start()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            \n",
    "            inputs = batch['tokens']\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            inputs = collator(inputs)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            labels = labels.to(self.device)\n",
    "            batchsize = len(labels)\n",
    "            \n",
    "            with autocast(enabled=self.apex):\n",
    "                outputs = self.model(inputs)\n",
    "                outputs = outputs.squeeze() if self.num_labels == 1 else outputs\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            total_loss.update(loss.item(), batchsize)\n",
    "            \n",
    "            current_lr = self.scheduler.get_lr()[0]\n",
    "            \n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            if self.clip_grad_norm:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                grad_norm = nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if step % self.verbose_step == 0 or step == (len(train_loader) - 1):\n",
    "                self.log(\n",
    "                    f'[TRAIN_F{self.current_fold}], ' + \\\n",
    "                    f'E: {self.current_epoch + 1}/{self.num_epochs}, ' + \\\n",
    "                    f'S: {str(step).zfill(len(str(len(train_loader))))}/{len(train_loader)}, ' + \\\n",
    "                    f'L: {total_loss.get_average():.5f}, ' + \\\n",
    "                    f'LR: {current_lr:.8f}, ' + \\\n",
    "#                     f'G: {grad_norm:.4f}, ' + \\\n",
    "                    f'T: {Timer.formatting(timer.get_time())}'\n",
    "                )\n",
    "            \n",
    "            # end of the train loop\n",
    "            if self.debug_run: break\n",
    "        \n",
    "        timer.stop()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "        return total_loss.get_average() \n",
    "        \n",
    "    def _valid_fn(self, valid_loader):\n",
    "        self.log(\"\\nVALID_LOOP\")\n",
    "        self.model.eval()\n",
    "\n",
    "        total_loss = Averager()\n",
    "        timer = Timer()\n",
    "        timer.start()\n",
    "        \n",
    "        ids_list = []\n",
    "        outputs_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        for step, batch in enumerate(valid_loader):\n",
    "            \n",
    "            ids = batch['ids']\n",
    "            inputs = batch['tokens']\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            inputs = collator(inputs)\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            labels = labels.to(self.device)\n",
    "            batchsize = len(labels)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(inputs)\n",
    "                outputs = outputs.squeeze() if self.num_labels == 1 else outputs\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "            total_loss.update(loss.item(), batchsize)\n",
    "            _ = [ids_list.append(i) for i in ids]\n",
    "            labels_list.append(labels.view(-1) if labels.size() == torch.Size([]) else labels)\n",
    "            outputs_list.append(outputs.view(-1) if outputs.size() == torch.Size([]) else outputs)\n",
    "            \n",
    "            if step % self.verbose_step == 0 or step == (len(valid_loader) - 1):\n",
    "                self.log(\n",
    "                    f'[VALID_F{self.current_fold}], ' + \\\n",
    "                    f'E: {self.current_epoch + 1}/{self.num_epochs}, ' + \\\n",
    "                    f'S: {str(step).zfill(len(str(len(valid_loader))))}/{len(valid_loader)}, ' + \\\n",
    "                    f'L: {total_loss.get_average():.5f}, ' + \\\n",
    "                    f'T: {Timer.formatting(timer.get_time())}'\n",
    "                )\n",
    "            if self.debug_run: break\n",
    "            # end of the valid loop\n",
    "\n",
    "        labels_list = torch.cat(labels_list)\n",
    "        outputs_list = torch.cat(outputs_list)\n",
    "        \n",
    "        timer.stop()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return total_loss.get_average(), ids_list, labels_list, outputs_list\n",
    "    \n",
    "    def _compare_and_save(self, qwk_score, train_loss, valid_loss, y_preds, raw_y_preds):\n",
    "        if qwk_score > self.best_qwk_score:\n",
    "            self.best_qwk_score = qwk_score\n",
    "            self.best_train_loss = train_loss\n",
    "            self.best_valid_loss = valid_loss\n",
    "            self.best_fold_y_preds = y_preds\n",
    "            self.best_fold_y_preds_raw = raw_y_preds\n",
    "            \n",
    "            file_name = f'best_score_fold{self.current_fold}.pt'\n",
    "            \n",
    "            self.model.eval()\n",
    "            torch.save({\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'best_train_loss': self.best_train_loss,\n",
    "                'best_valid_loss': self.best_valid_loss,\n",
    "                'best_qwk_score': self.best_qwk_score,\n",
    "            }, Path(self.save_path, file_name))\n",
    "            \n",
    "            self.log(f'\\n-> [SAVED] Fold: {self.current_fold}, Epoch: {self.current_epoch + 1}, QWK: {self.best_qwk_score}\\n')\n",
    "            \n",
    "    def _record(self, new_record_values):\n",
    "        new_record_dict = {k: [v] for k, v in zip(self.record_df_columns, new_record_values)}\n",
    "        new_record = pd.DataFrame.from_dict(new_record_dict)\n",
    "        self.record_df = pd.concat([self.record_df, new_record], axis=0)\n",
    "\n",
    "    def log(self, msg):\n",
    "        print(msg)\n",
    "        if not self.debug_run:\n",
    "            with open(Path(self.save_path, 'train.log'), mode='a+', encoding='utf-8') as log:\n",
    "                log.write(f'{msg}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b827f",
   "metadata": {
    "papermill": {
     "duration": 0.008404,
     "end_time": "2024-06-30T04:46:29.390492",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.382088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf1ff9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.408839Z",
     "iopub.status.busy": "2024-06-30T04:46:29.408503Z",
     "iopub.status.idle": "2024-06-30T04:46:29.416468Z",
     "shell.execute_reply": "2024-06-30T04:46:29.415641Z"
    },
    "papermill": {
     "duration": 0.019587,
     "end_time": "2024-06-30T04:46:29.418576",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.398989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONF:\n",
    "    exp = '200'\n",
    "    \n",
    "    data_path = \"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/\"\n",
    "    extra_data_path = '/kaggle/input/lal-aes2-create-prompt-data/cleaned_persaude.csv'\n",
    "    save_path = '/kaggle/working/'\n",
    "    \n",
    "    train_col = 'full_text'\n",
    "    target_col = 'label'\n",
    "    num_labels = 1  # 1 for mse and bce, 6 for ce\n",
    "\n",
    "    seed = 42\n",
    "    num_folds = 4\n",
    "    train_fold_list = [0, 1, 2, 3]\n",
    "    cv_strat = 'multilabel_stratified_kfold' # ['stratified_kfold', 'stratified_group_kfold', 'group_kfold', 'multilabel_stratified_kfold']\n",
    "\n",
    "    model_name = 'microsoft/deberta-v3-base'\n",
    "    pooling_layer = 'mean_pooling'\n",
    "    # ['mean_pooling', 'concat_pooling', 'weighted_layer_pooling', 'lstm_pooling', 'gem_pooling', 'attention_pooling']\n",
    "\n",
    "    wlp_layer_start = 4\n",
    "    ccp_pooling_last = 4\n",
    "    lstm_hidden = 768\n",
    "\n",
    "    gradient_checkpointing = True\n",
    "    freeze_embeddings = False\n",
    "    freeze_n_layers = 0\n",
    "    optimizer = 'adamw'\n",
    "    optim_eps = 1e-6\n",
    "    optim_betas1 = 0.9\n",
    "    optim_betas2 = 0.999\n",
    "    scheduler = 'linear_warmup' # ['cosine_warmup', 'linear_warmup', 'poly_warmup', 'constant_warmup']\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-5\n",
    "    layerwise_lr_decay = 0.9\n",
    "    weight_decay = 0.01\n",
    "    multi_dropout = False # DO NOT USE THIS WITH REGRESSION\n",
    "    criterion = 'mse' # ['mse', 'ce', 'bce', 'huber']\n",
    "    apex = True\n",
    "    max_len = 1024\n",
    "    batch_size = 8\n",
    "    num_epochs = 3\n",
    "    warmup_ratios = 0.0\n",
    "    poly_power = 0.05\n",
    "    verbose_step = 200\n",
    "    clip_grad_norm = True\n",
    "    max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6620997",
   "metadata": {
    "papermill": {
     "duration": 0.008609,
     "end_time": "2024-06-30T04:46:29.435610",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.427001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f791d8c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:29.454371Z",
     "iopub.status.busy": "2024-06-30T04:46:29.454016Z",
     "iopub.status.idle": "2024-06-30T04:46:31.126704Z",
     "shell.execute_reply": "2024-06-30T04:46:31.125743Z"
    },
    "papermill": {
     "duration": 1.68515,
     "end_time": "2024-06-30T04:46:31.129129",
     "exception": false,
     "start_time": "2024-06-30T04:46:29.443979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(CONF.data_path + \"train.csv\")\n",
    "# train_df_with_prompt = pd.read_csv('/kaggle/input/lal-aes2-create-prompt-data/train_df_with_prompt.csv')\n",
    "\n",
    "train_df_with_prompt = pl.read_csv('/kaggle/input/lal-aes2-create-tokened-text/train_combined_tokened.csv')\n",
    "\n",
    "included_token = ['Position', 'Evidence', 'Concluding', 'Rebuttal']\n",
    "\n",
    "all_token = ['Lead', 'Position', 'Claim', 'Evidence', 'Concluding', 'Counterclaim', 'Rebuttal']\n",
    "token_filter_pat = ''.join(['<(Unannotated'] + [f'|{t}' for t in all_token if t not in included_token] + [')>'])\n",
    "\n",
    "train_df_with_prompt = train_df_with_prompt.with_columns(pl.col('tokened_text').str.replace_all(token_filter_pat, '')).to_pandas()\n",
    "\n",
    "# remove_topics = ['Car-free cities', 'Does the electoral college work?']\n",
    "# train_df_with_prompt =  train_df_with_prompt[~train_df_with_prompt['prompt_name'].isin(remove_topics)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0a7da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:31.148480Z",
     "iopub.status.busy": "2024-06-30T04:46:31.147645Z",
     "iopub.status.idle": "2024-06-30T04:46:31.152082Z",
     "shell.execute_reply": "2024-06-30T04:46:31.151219Z"
    },
    "papermill": {
     "duration": 0.015937,
     "end_time": "2024-06-30T04:46:31.154025",
     "exception": false,
     "start_time": "2024-06-30T04:46:31.138088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## debugging\n",
    "# cfg = CONF()\n",
    "# tokenizer = get_tokenizer(cfg)\n",
    "# df = preprocess_data(train_df_with_prompt)\n",
    "# df = split_fold(cfg, df)\n",
    "## train_dataset = AE2Dataset(cfg, df[df['fold'] != 0], tokenizer, output_tokens_only=True)\n",
    "# train_loader, valild_loader = get_dataloader(cfg, df, tokenizer, 0)\n",
    "# model = get_model(CONF)\n",
    "# for _ , (inputs, labels) in enumerate(train_loader):\n",
    "#     inputs = collator(inputs)\n",
    "#     outputs = model(inputs)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b173e78",
   "metadata": {
    "papermill": {
     "duration": 0.008397,
     "end_time": "2024-06-30T04:46:31.170951",
     "exception": false,
     "start_time": "2024-06-30T04:46:31.162554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d130e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:31.189279Z",
     "iopub.status.busy": "2024-06-30T04:46:31.188967Z",
     "iopub.status.idle": "2024-06-30T04:46:31.204889Z",
     "shell.execute_reply": "2024-06-30T04:46:31.204133Z"
    },
    "papermill": {
     "duration": 0.027548,
     "end_time": "2024-06-30T04:46:31.206845",
     "exception": false,
     "start_time": "2024-06-30T04:46:31.179297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(conf, df, debug_run=True, pretrained_path=None):\n",
    "    seed_everything(conf.seed)\n",
    "    cv_record_df = pd.DataFrame()\n",
    "    oof_df = pd.DataFrame()\n",
    "\n",
    "    extract_config(conf)\n",
    "    df = preprocess_data(df)\n",
    "    df = split_fold(conf, df)\n",
    "    print(df.groupby('fold').size())\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    if debug_run:\n",
    "        print(\"DEBUG_RUN\")\n",
    "        conf.batch_size = 2\n",
    "\n",
    "    for f in conf.train_fold_list:\n",
    "        seed_everything(conf.seed)\n",
    "        tokenizer = get_tokenizer(conf)\n",
    "        train_loader, valid_loader = get_dataloader(conf, df, tokenizer, f)\n",
    "        if not pretrained_path:\n",
    "            model = get_model(conf)\n",
    "        else:\n",
    "            model = load_model(conf, f, device, pretrained_path)\n",
    "        model.backbone.resize_token_embeddings(len(tokenizer))\n",
    "        optimizer = get_optimizer(conf)\n",
    "        optim_params = get_optimizer_grouped_params(conf, model) # LLRD\n",
    "#         optim_params = get_optimizer_params(conf, model) # Diff LR\n",
    "        scheduler, scheduler_hparams = get_scheduler(conf, len(train_loader))\n",
    "        criterion = get_criterion(conf)\n",
    "\n",
    "        trainer = Trainer(debug_run, f, conf, device, model, optimizer, optim_params, scheduler, scheduler_hparams, criterion)\n",
    "        record_df, fold_preds_df = trainer.fit(train_loader, valid_loader)\n",
    "\n",
    "        oof_df = pd.concat([oof_df, fold_preds_df], axis=0)\n",
    "        cv_record_df = pd.concat([cv_record_df, record_df], axis=0)\n",
    "\n",
    "        if debug_run and len(conf.train_fold_list) == 1: break\n",
    "\n",
    "    oof_df = oof_df.sort_values(by='essay_id').reset_index(drop=True)\n",
    "    score_df = df.copy().merge(oof_df, on='essay_id', how='inner')\n",
    "    if conf.num_labels == 1:\n",
    "        y_trues = score_df['score_x'].values\n",
    "        y_preds = score_df['score_y'].values\n",
    "    else:\n",
    "        y_trues = score_df['score'].values\n",
    "        y_preds = score_df['pred_c'].values\n",
    "    qwk = cohen_kappa_score(y_trues, y_preds, weights='quadratic')\n",
    "    overall_cv = pd.DataFrame({'fold': [np.nan], 'epoch': [np.nan], 'train_loss': [np.nan], 'valid_loss': [np.nan], 'qwk_score': [qwk]})\n",
    "    cv_record_df = pd.concat([cv_record_df, overall_cv], axis=0).reset_index(drop=True)\n",
    "    best_epoch_idx = [cv_record_df[cv_record_df['fold'] == i]['qwk_score'].idxmax() for i in conf.train_fold_list]\n",
    "    best_epoch_record  = pd.concat([cv_record_df[cv_record_df.index.isin(best_epoch_idx)], overall_cv], axis=0).reset_index(drop=True)\n",
    "\n",
    "    display(cv_record_df)\n",
    "    display(best_epoch_record)\n",
    "    cv_record_df.to_csv(conf.save_path + 'cv_record.csv', index=False)\n",
    "    best_epoch_record.to_csv(conf.save_path + 'best_epoch_record.csv', index=False)\n",
    "    oof_df.to_csv(conf.save_path + 'oof_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f5871",
   "metadata": {
    "papermill": {
     "duration": 0.008351,
     "end_time": "2024-06-30T04:46:31.223683",
     "exception": false,
     "start_time": "2024-06-30T04:46:31.215332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db55317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T04:46:31.242333Z",
     "iopub.status.busy": "2024-06-30T04:46:31.241555Z",
     "iopub.status.idle": "2024-06-30T12:40:11.480945Z",
     "shell.execute_reply": "2024-06-30T12:40:11.479998Z"
    },
    "papermill": {
     "duration": 28420.251233,
     "end_time": "2024-06-30T12:40:11.483388",
     "exception": false,
     "start_time": "2024-06-30T04:46:31.232155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted config\n",
      "fold\n",
      "0    4326\n",
      "1    4326\n",
      "2    4327\n",
      "3    4326\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a24e74b62949a999ed3dba2ce19023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8212a8b7389e430e88a7b55235436a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b89257b59c4706bec3201288cbffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3af92e36834446a88d5b88fe5971d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp: 200\n",
      "--- FOLD 0 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 1/3, S: 0000/1622, L: 5.89558, LR: 0.00001000, T: 0:00:02\n",
      "[TRAIN_F0], E: 1/3, S: 0200/1622, L: 0.73856, LR: 0.00000959, T: 0:04:31\n",
      "[TRAIN_F0], E: 1/3, S: 0400/1622, L: 0.58617, LR: 0.00000918, T: 0:08:54\n",
      "[TRAIN_F0], E: 1/3, S: 0600/1622, L: 0.51282, LR: 0.00000877, T: 0:13:17\n",
      "[TRAIN_F0], E: 1/3, S: 0800/1622, L: 0.47523, LR: 0.00000836, T: 0:17:42\n",
      "[TRAIN_F0], E: 1/3, S: 1000/1622, L: 0.45235, LR: 0.00000794, T: 0:22:06\n",
      "[TRAIN_F0], E: 1/3, S: 1200/1622, L: 0.43199, LR: 0.00000753, T: 0:26:38\n",
      "[TRAIN_F0], E: 1/3, S: 1400/1622, L: 0.42038, LR: 0.00000712, T: 0:31:16\n",
      "[TRAIN_F0], E: 1/3, S: 1600/1622, L: 0.40932, LR: 0.00000671, T: 0:35:48\n",
      "[TRAIN_F0], E: 1/3, S: 1621/1622, L: 0.40807, LR: 0.00000667, T: 0:36:15\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 1/3, S: 000/541, L: 0.41967, T: 0:00:01\n",
      "[VALID_F0], E: 1/3, S: 200/541, L: 0.32224, T: 0:01:09\n",
      "[VALID_F0], E: 1/3, S: 400/541, L: 0.32552, T: 0:02:21\n",
      "[VALID_F0], E: 1/3, S: 540/541, L: 0.32632, T: 0:03:11\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 1, QWK: 0.7694932389510014\n",
      "\n",
      "-- [Fold: 0, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 2/3, S: 0000/1622, L: 0.14165, LR: 0.00000667, T: 0:00:01\n",
      "[TRAIN_F0], E: 2/3, S: 0200/1622, L: 0.30992, LR: 0.00000626, T: 0:04:30\n",
      "[TRAIN_F0], E: 2/3, S: 0400/1622, L: 0.28797, LR: 0.00000584, T: 0:09:05\n",
      "[TRAIN_F0], E: 2/3, S: 0600/1622, L: 0.28888, LR: 0.00000543, T: 0:13:27\n",
      "[TRAIN_F0], E: 2/3, S: 0800/1622, L: 0.28687, LR: 0.00000502, T: 0:17:56\n",
      "[TRAIN_F0], E: 2/3, S: 1000/1622, L: 0.28745, LR: 0.00000461, T: 0:22:27\n",
      "[TRAIN_F0], E: 2/3, S: 1200/1622, L: 0.28368, LR: 0.00000420, T: 0:26:55\n",
      "[TRAIN_F0], E: 2/3, S: 1400/1622, L: 0.28298, LR: 0.00000379, T: 0:31:21\n",
      "[TRAIN_F0], E: 2/3, S: 1600/1622, L: 0.28349, LR: 0.00000338, T: 0:36:01\n",
      "[TRAIN_F0], E: 2/3, S: 1621/1622, L: 0.28285, LR: 0.00000334, T: 0:36:27\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 2/3, S: 000/541, L: 0.51104, T: 0:00:00\n",
      "[VALID_F0], E: 2/3, S: 200/541, L: 0.30028, T: 0:01:09\n",
      "[VALID_F0], E: 2/3, S: 400/541, L: 0.30079, T: 0:02:21\n",
      "[VALID_F0], E: 2/3, S: 540/541, L: 0.30390, T: 0:03:11\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 2, QWK: 0.8041304800203027\n",
      "\n",
      "-- [Fold: 0, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F0], E: 3/3, S: 0000/1622, L: 0.39654, LR: 0.00000333, T: 0:00:01\n",
      "[TRAIN_F0], E: 3/3, S: 0200/1622, L: 0.25708, LR: 0.00000292, T: 0:04:25\n",
      "[TRAIN_F0], E: 3/3, S: 0400/1622, L: 0.24948, LR: 0.00000251, T: 0:08:59\n",
      "[TRAIN_F0], E: 3/3, S: 0600/1622, L: 0.24482, LR: 0.00000210, T: 0:13:30\n",
      "[TRAIN_F0], E: 3/3, S: 0800/1622, L: 0.24099, LR: 0.00000169, T: 0:17:50\n",
      "[TRAIN_F0], E: 3/3, S: 1000/1622, L: 0.23793, LR: 0.00000128, T: 0:22:16\n",
      "[TRAIN_F0], E: 3/3, S: 1200/1622, L: 0.23639, LR: 0.00000087, T: 0:26:54\n",
      "[TRAIN_F0], E: 3/3, S: 1400/1622, L: 0.23544, LR: 0.00000046, T: 0:31:21\n",
      "[TRAIN_F0], E: 3/3, S: 1600/1622, L: 0.23430, LR: 0.00000005, T: 0:36:00\n",
      "[TRAIN_F0], E: 3/3, S: 1621/1622, L: 0.23451, LR: 0.00000000, T: 0:36:29\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F0], E: 3/3, S: 000/541, L: 0.39536, T: 0:00:00\n",
      "[VALID_F0], E: 3/3, S: 200/541, L: 0.27983, T: 0:01:09\n",
      "[VALID_F0], E: 3/3, S: 400/541, L: 0.28262, T: 0:02:21\n",
      "[VALID_F0], E: 3/3, S: 540/541, L: 0.28596, T: 0:03:11\n",
      "\n",
      "-> [SAVED] Fold: 0, Epoch: 3, QWK: 0.8215751166284307\n",
      "\n",
      "-- [Fold: 0, Epoch: 3] DONE --\n",
      "\n",
      "exp: 200\n",
      "--- FOLD 1 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 1/3, S: 0000/1622, L: 5.54339, LR: 0.00001000, T: 0:00:02\n",
      "[TRAIN_F1], E: 1/3, S: 0200/1622, L: 0.76393, LR: 0.00000959, T: 0:04:36\n",
      "[TRAIN_F1], E: 1/3, S: 0400/1622, L: 0.58352, LR: 0.00000918, T: 0:09:12\n",
      "[TRAIN_F1], E: 1/3, S: 0600/1622, L: 0.52802, LR: 0.00000877, T: 0:13:31\n",
      "[TRAIN_F1], E: 1/3, S: 0800/1622, L: 0.47895, LR: 0.00000836, T: 0:17:55\n",
      "[TRAIN_F1], E: 1/3, S: 1000/1622, L: 0.45460, LR: 0.00000794, T: 0:22:18\n",
      "[TRAIN_F1], E: 1/3, S: 1200/1622, L: 0.43858, LR: 0.00000753, T: 0:26:39\n",
      "[TRAIN_F1], E: 1/3, S: 1400/1622, L: 0.42659, LR: 0.00000712, T: 0:31:07\n",
      "[TRAIN_F1], E: 1/3, S: 1600/1622, L: 0.41525, LR: 0.00000671, T: 0:35:27\n",
      "[TRAIN_F1], E: 1/3, S: 1621/1622, L: 0.41392, LR: 0.00000667, T: 0:35:54\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 1/3, S: 000/541, L: 0.08655, T: 0:00:01\n",
      "[VALID_F1], E: 1/3, S: 200/541, L: 0.33828, T: 0:01:13\n",
      "[VALID_F1], E: 1/3, S: 400/541, L: 0.33155, T: 0:02:23\n",
      "[VALID_F1], E: 1/3, S: 540/541, L: 0.32677, T: 0:03:14\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 1, QWK: 0.8066500992287284\n",
      "\n",
      "-- [Fold: 1, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 2/3, S: 0000/1622, L: 0.14109, LR: 0.00000667, T: 0:00:01\n",
      "[TRAIN_F1], E: 2/3, S: 0200/1622, L: 0.31298, LR: 0.00000626, T: 0:04:24\n",
      "[TRAIN_F1], E: 2/3, S: 0400/1622, L: 0.30240, LR: 0.00000584, T: 0:08:42\n",
      "[TRAIN_F1], E: 2/3, S: 0600/1622, L: 0.30372, LR: 0.00000543, T: 0:13:24\n",
      "[TRAIN_F1], E: 2/3, S: 0800/1622, L: 0.29974, LR: 0.00000502, T: 0:17:49\n",
      "[TRAIN_F1], E: 2/3, S: 1000/1622, L: 0.29384, LR: 0.00000461, T: 0:22:14\n",
      "[TRAIN_F1], E: 2/3, S: 1200/1622, L: 0.28524, LR: 0.00000420, T: 0:26:43\n",
      "[TRAIN_F1], E: 2/3, S: 1400/1622, L: 0.28407, LR: 0.00000379, T: 0:31:11\n",
      "[TRAIN_F1], E: 2/3, S: 1600/1622, L: 0.28272, LR: 0.00000338, T: 0:35:31\n",
      "[TRAIN_F1], E: 2/3, S: 1621/1622, L: 0.28300, LR: 0.00000334, T: 0:35:59\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 2/3, S: 000/541, L: 0.08019, T: 0:00:01\n",
      "[VALID_F1], E: 2/3, S: 200/541, L: 0.30953, T: 0:01:13\n",
      "[VALID_F1], E: 2/3, S: 400/541, L: 0.31006, T: 0:02:23\n",
      "[VALID_F1], E: 2/3, S: 540/541, L: 0.30314, T: 0:03:14\n",
      "-- [Fold: 1, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F1], E: 3/3, S: 0000/1622, L: 0.17053, LR: 0.00000333, T: 0:00:01\n",
      "[TRAIN_F1], E: 3/3, S: 0200/1622, L: 0.25377, LR: 0.00000292, T: 0:04:28\n",
      "[TRAIN_F1], E: 3/3, S: 0400/1622, L: 0.24028, LR: 0.00000251, T: 0:08:43\n",
      "[TRAIN_F1], E: 3/3, S: 0600/1622, L: 0.24041, LR: 0.00000210, T: 0:13:14\n",
      "[TRAIN_F1], E: 3/3, S: 0800/1622, L: 0.23943, LR: 0.00000169, T: 0:17:36\n",
      "[TRAIN_F1], E: 3/3, S: 1000/1622, L: 0.24076, LR: 0.00000128, T: 0:22:10\n",
      "[TRAIN_F1], E: 3/3, S: 1200/1622, L: 0.23847, LR: 0.00000087, T: 0:26:43\n",
      "[TRAIN_F1], E: 3/3, S: 1400/1622, L: 0.23784, LR: 0.00000046, T: 0:31:09\n",
      "[TRAIN_F1], E: 3/3, S: 1600/1622, L: 0.23652, LR: 0.00000005, T: 0:35:38\n",
      "[TRAIN_F1], E: 3/3, S: 1621/1622, L: 0.23675, LR: 0.00000000, T: 0:36:06\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F1], E: 3/3, S: 000/541, L: 0.06527, T: 0:00:01\n",
      "[VALID_F1], E: 3/3, S: 200/541, L: 0.29662, T: 0:01:13\n",
      "[VALID_F1], E: 3/3, S: 400/541, L: 0.29603, T: 0:02:23\n",
      "[VALID_F1], E: 3/3, S: 540/541, L: 0.28960, T: 0:03:14\n",
      "\n",
      "-> [SAVED] Fold: 1, Epoch: 3, QWK: 0.8192211274635045\n",
      "\n",
      "-- [Fold: 1, Epoch: 3] DONE --\n",
      "\n",
      "exp: 200\n",
      "--- FOLD 2 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 1/3, S: 0000/1622, L: 2.38929, LR: 0.00001000, T: 0:00:01\n",
      "[TRAIN_F2], E: 1/3, S: 0200/1622, L: 0.70419, LR: 0.00000959, T: 0:04:26\n",
      "[TRAIN_F2], E: 1/3, S: 0400/1622, L: 0.55458, LR: 0.00000918, T: 0:08:50\n",
      "[TRAIN_F2], E: 1/3, S: 0600/1622, L: 0.50360, LR: 0.00000877, T: 0:13:16\n",
      "[TRAIN_F2], E: 1/3, S: 0800/1622, L: 0.46936, LR: 0.00000836, T: 0:17:39\n",
      "[TRAIN_F2], E: 1/3, S: 1000/1622, L: 0.44599, LR: 0.00000794, T: 0:22:08\n",
      "[TRAIN_F2], E: 1/3, S: 1200/1622, L: 0.43352, LR: 0.00000753, T: 0:26:39\n",
      "[TRAIN_F2], E: 1/3, S: 1400/1622, L: 0.42282, LR: 0.00000712, T: 0:31:06\n",
      "[TRAIN_F2], E: 1/3, S: 1600/1622, L: 0.41050, LR: 0.00000671, T: 0:35:39\n",
      "[TRAIN_F2], E: 1/3, S: 1621/1622, L: 0.40947, LR: 0.00000667, T: 0:36:01\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 1/3, S: 000/541, L: 0.15083, T: 0:00:01\n",
      "[VALID_F2], E: 1/3, S: 200/541, L: 0.34311, T: 0:01:11\n",
      "[VALID_F2], E: 1/3, S: 400/541, L: 0.33718, T: 0:02:25\n",
      "[VALID_F2], E: 1/3, S: 540/541, L: 0.33867, T: 0:03:16\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 1, QWK: 0.7618171073219387\n",
      "\n",
      "-- [Fold: 2, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 2/3, S: 0000/1622, L: 0.14570, LR: 0.00000667, T: 0:00:02\n",
      "[TRAIN_F2], E: 2/3, S: 0200/1622, L: 0.28270, LR: 0.00000626, T: 0:04:31\n",
      "[TRAIN_F2], E: 2/3, S: 0400/1622, L: 0.29393, LR: 0.00000584, T: 0:09:05\n",
      "[TRAIN_F2], E: 2/3, S: 0600/1622, L: 0.28642, LR: 0.00000543, T: 0:13:22\n",
      "[TRAIN_F2], E: 2/3, S: 0800/1622, L: 0.28566, LR: 0.00000502, T: 0:17:54\n",
      "[TRAIN_F2], E: 2/3, S: 1000/1622, L: 0.28332, LR: 0.00000461, T: 0:22:19\n",
      "[TRAIN_F2], E: 2/3, S: 1200/1622, L: 0.28319, LR: 0.00000420, T: 0:26:47\n",
      "[TRAIN_F2], E: 2/3, S: 1400/1622, L: 0.28208, LR: 0.00000379, T: 0:31:09\n",
      "[TRAIN_F2], E: 2/3, S: 1600/1622, L: 0.28349, LR: 0.00000338, T: 0:35:30\n",
      "[TRAIN_F2], E: 2/3, S: 1621/1622, L: 0.28349, LR: 0.00000334, T: 0:35:57\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 2/3, S: 000/541, L: 0.11121, T: 0:00:01\n",
      "[VALID_F2], E: 2/3, S: 200/541, L: 0.29272, T: 0:01:11\n",
      "[VALID_F2], E: 2/3, S: 400/541, L: 0.28917, T: 0:02:25\n",
      "[VALID_F2], E: 2/3, S: 540/541, L: 0.29120, T: 0:03:17\n",
      "\n",
      "-> [SAVED] Fold: 2, Epoch: 2, QWK: 0.8346017146048499\n",
      "\n",
      "-- [Fold: 2, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F2], E: 3/3, S: 0000/1622, L: 0.20137, LR: 0.00000333, T: 0:00:02\n",
      "[TRAIN_F2], E: 3/3, S: 0200/1622, L: 0.25773, LR: 0.00000292, T: 0:04:32\n",
      "[TRAIN_F2], E: 3/3, S: 0400/1622, L: 0.24970, LR: 0.00000251, T: 0:08:51\n",
      "[TRAIN_F2], E: 3/3, S: 0600/1622, L: 0.24151, LR: 0.00000210, T: 0:13:20\n",
      "[TRAIN_F2], E: 3/3, S: 0800/1622, L: 0.23761, LR: 0.00000169, T: 0:17:51\n",
      "[TRAIN_F2], E: 3/3, S: 1000/1622, L: 0.23593, LR: 0.00000128, T: 0:22:12\n",
      "[TRAIN_F2], E: 3/3, S: 1200/1622, L: 0.23677, LR: 0.00000087, T: 0:26:32\n",
      "[TRAIN_F2], E: 3/3, S: 1400/1622, L: 0.23598, LR: 0.00000046, T: 0:31:08\n",
      "[TRAIN_F2], E: 3/3, S: 1600/1622, L: 0.23533, LR: 0.00000005, T: 0:35:28\n",
      "[TRAIN_F2], E: 3/3, S: 1621/1622, L: 0.23532, LR: 0.00000000, T: 0:35:57\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F2], E: 3/3, S: 000/541, L: 0.13797, T: 0:00:01\n",
      "[VALID_F2], E: 3/3, S: 200/541, L: 0.28648, T: 0:01:11\n",
      "[VALID_F2], E: 3/3, S: 400/541, L: 0.28137, T: 0:02:25\n",
      "[VALID_F2], E: 3/3, S: 540/541, L: 0.28162, T: 0:03:16\n",
      "-- [Fold: 2, Epoch: 3] DONE --\n",
      "\n",
      "exp: 200\n",
      "--- FOLD 3 ---\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 1/3, S: 0000/1622, L: 2.28275, LR: 0.00001000, T: 0:00:01\n",
      "[TRAIN_F3], E: 1/3, S: 0200/1622, L: 0.72054, LR: 0.00000959, T: 0:04:38\n",
      "[TRAIN_F3], E: 1/3, S: 0400/1622, L: 0.57588, LR: 0.00000918, T: 0:09:00\n",
      "[TRAIN_F3], E: 1/3, S: 0600/1622, L: 0.50853, LR: 0.00000877, T: 0:13:33\n",
      "[TRAIN_F3], E: 1/3, S: 0800/1622, L: 0.46888, LR: 0.00000836, T: 0:17:56\n",
      "[TRAIN_F3], E: 1/3, S: 1000/1622, L: 0.44760, LR: 0.00000794, T: 0:22:23\n",
      "[TRAIN_F3], E: 1/3, S: 1200/1622, L: 0.43181, LR: 0.00000753, T: 0:26:55\n",
      "[TRAIN_F3], E: 1/3, S: 1400/1622, L: 0.42340, LR: 0.00000712, T: 0:31:29\n",
      "[TRAIN_F3], E: 1/3, S: 1600/1622, L: 0.41087, LR: 0.00000671, T: 0:35:53\n",
      "[TRAIN_F3], E: 1/3, S: 1621/1622, L: 0.40994, LR: 0.00000667, T: 0:36:20\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 1/3, S: 000/541, L: 0.14032, T: 0:00:01\n",
      "[VALID_F3], E: 1/3, S: 200/541, L: 0.33434, T: 0:01:12\n",
      "[VALID_F3], E: 1/3, S: 400/541, L: 0.33343, T: 0:02:20\n",
      "[VALID_F3], E: 1/3, S: 540/541, L: 0.33700, T: 0:03:10\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 1, QWK: 0.7991929617030702\n",
      "\n",
      "-- [Fold: 3, Epoch: 1] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 2/3, S: 0000/1622, L: 0.40018, LR: 0.00000667, T: 0:00:02\n",
      "[TRAIN_F3], E: 2/3, S: 0200/1622, L: 0.30481, LR: 0.00000626, T: 0:04:40\n",
      "[TRAIN_F3], E: 2/3, S: 0400/1622, L: 0.29461, LR: 0.00000584, T: 0:08:56\n",
      "[TRAIN_F3], E: 2/3, S: 0600/1622, L: 0.29508, LR: 0.00000543, T: 0:13:33\n",
      "[TRAIN_F3], E: 2/3, S: 0800/1622, L: 0.29094, LR: 0.00000502, T: 0:18:04\n",
      "[TRAIN_F3], E: 2/3, S: 1000/1622, L: 0.28728, LR: 0.00000461, T: 0:22:39\n",
      "[TRAIN_F3], E: 2/3, S: 1200/1622, L: 0.28577, LR: 0.00000420, T: 0:26:59\n",
      "[TRAIN_F3], E: 2/3, S: 1400/1622, L: 0.28741, LR: 0.00000379, T: 0:31:29\n",
      "[TRAIN_F3], E: 2/3, S: 1600/1622, L: 0.28610, LR: 0.00000338, T: 0:35:59\n",
      "[TRAIN_F3], E: 2/3, S: 1621/1622, L: 0.28560, LR: 0.00000334, T: 0:36:26\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 2/3, S: 000/541, L: 0.08335, T: 0:00:00\n",
      "[VALID_F3], E: 2/3, S: 200/541, L: 0.30062, T: 0:01:12\n",
      "[VALID_F3], E: 2/3, S: 400/541, L: 0.29685, T: 0:02:20\n",
      "[VALID_F3], E: 2/3, S: 540/541, L: 0.30231, T: 0:03:10\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 2, QWK: 0.8189405232907461\n",
      "\n",
      "-- [Fold: 3, Epoch: 2] DONE --\n",
      "\n",
      "TRAINL_LOOP\n",
      "[TRAIN_F3], E: 3/3, S: 0000/1622, L: 0.19801, LR: 0.00000333, T: 0:00:01\n",
      "[TRAIN_F3], E: 3/3, S: 0200/1622, L: 0.24119, LR: 0.00000292, T: 0:04:39\n",
      "[TRAIN_F3], E: 3/3, S: 0400/1622, L: 0.24499, LR: 0.00000251, T: 0:09:06\n",
      "[TRAIN_F3], E: 3/3, S: 0600/1622, L: 0.24488, LR: 0.00000210, T: 0:13:36\n",
      "[TRAIN_F3], E: 3/3, S: 0800/1622, L: 0.24539, LR: 0.00000169, T: 0:18:04\n",
      "[TRAIN_F3], E: 3/3, S: 1000/1622, L: 0.24522, LR: 0.00000128, T: 0:22:46\n",
      "[TRAIN_F3], E: 3/3, S: 1200/1622, L: 0.24334, LR: 0.00000087, T: 0:27:08\n",
      "[TRAIN_F3], E: 3/3, S: 1400/1622, L: 0.23949, LR: 0.00000046, T: 0:31:30\n",
      "[TRAIN_F3], E: 3/3, S: 1600/1622, L: 0.23684, LR: 0.00000005, T: 0:35:57\n",
      "[TRAIN_F3], E: 3/3, S: 1621/1622, L: 0.23703, LR: 0.00000000, T: 0:36:24\n",
      "\n",
      "VALID_LOOP\n",
      "[VALID_F3], E: 3/3, S: 000/541, L: 0.08091, T: 0:00:01\n",
      "[VALID_F3], E: 3/3, S: 200/541, L: 0.28353, T: 0:01:12\n",
      "[VALID_F3], E: 3/3, S: 400/541, L: 0.28215, T: 0:02:20\n",
      "[VALID_F3], E: 3/3, S: 540/541, L: 0.28880, T: 0:03:09\n",
      "\n",
      "-> [SAVED] Fold: 3, Epoch: 3, QWK: 0.8216206843064893\n",
      "\n",
      "-- [Fold: 3, Epoch: 3] DONE --\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>qwk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408075</td>\n",
       "      <td>0.326321</td>\n",
       "      <td>0.769493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282846</td>\n",
       "      <td>0.303899</td>\n",
       "      <td>0.804130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234511</td>\n",
       "      <td>0.285956</td>\n",
       "      <td>0.821575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.413916</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.806650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.282998</td>\n",
       "      <td>0.303143</td>\n",
       "      <td>0.795432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.236754</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.819221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409470</td>\n",
       "      <td>0.338669</td>\n",
       "      <td>0.761817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283495</td>\n",
       "      <td>0.291195</td>\n",
       "      <td>0.834602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235320</td>\n",
       "      <td>0.281618</td>\n",
       "      <td>0.828678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.409942</td>\n",
       "      <td>0.336999</td>\n",
       "      <td>0.799193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285599</td>\n",
       "      <td>0.302315</td>\n",
       "      <td>0.818941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.237034</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.821621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold epoch  train_loss  valid_loss  qwk_score\n",
       "0     0     0    0.408075    0.326321   0.769493\n",
       "1     0     1    0.282846    0.303899   0.804130\n",
       "2     0     2    0.234511    0.285956   0.821575\n",
       "3     1     0    0.413916    0.326767   0.806650\n",
       "4     1     1    0.282998    0.303143   0.795432\n",
       "5     1     2    0.236754    0.289600   0.819221\n",
       "6     2     0    0.409470    0.338669   0.761817\n",
       "7     2     1    0.283495    0.291195   0.834602\n",
       "8     2     2    0.235320    0.281618   0.828678\n",
       "9     3     0    0.409942    0.336999   0.799193\n",
       "10    3     1    0.285599    0.302315   0.818941\n",
       "11    3     2    0.237034    0.288800   0.821621\n",
       "12  NaN   NaN         NaN         NaN   0.824406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>qwk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234511</td>\n",
       "      <td>0.285956</td>\n",
       "      <td>0.821575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.236754</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.819221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283495</td>\n",
       "      <td>0.291195</td>\n",
       "      <td>0.834602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.237034</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.821621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fold epoch  train_loss  valid_loss  qwk_score\n",
       "0    0     2    0.234511    0.285956   0.821575\n",
       "1    1     2    0.236754    0.289600   0.819221\n",
       "2    2     1    0.283495    0.291195   0.834602\n",
       "3    3     2    0.237034    0.288800   0.821621\n",
       "4  NaN   NaN         NaN         NaN   0.824406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_training(CONF, train_df_with_prompt, debug_run=False, pretrained_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00779ce",
   "metadata": {
    "papermill": {
     "duration": 0.023756,
     "end_time": "2024-06-30T12:40:11.531176",
     "exception": false,
     "start_time": "2024-06-30T12:40:11.507420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 5173939,
     "sourceId": 8738055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4902589,
     "sourceId": 8770944,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 177401657,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 183697732,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28460.913965,
   "end_time": "2024-06-30T12:40:14.973060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-30T04:45:54.059095",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2115429dc9884258a06e2608482e33c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "220dc9fc707e45ecac697ef9da557059": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22892d586a994f349bae332fee7c6040": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7668db0b7cfd40fe840b0d453b858c2b",
       "placeholder": "​",
       "style": "IPY_MODEL_e32e78ed3486421cbdff9da87a3d6f84",
       "value": "config.json: 100%"
      }
     },
     "28c174f839b149f1be31367085f14dec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2ff719df56ac4f34834efe8839da96a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "306b3b70c858433c9b8d0daa113cec02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35f12a23246c4767832c9d3ae22c25ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35f498e2d39b4112a6d0fc054e4358ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "406119625eb14ebfbc960b2ba55ec6f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec95a7dc4a034097bfda176df02429f5",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ede771eaa80453e958d80b70e5e46b7",
       "value": 52.0
      }
     },
     "4672ef56860143b9abcaf266a235f505": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35f498e2d39b4112a6d0fc054e4358ea",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b380ccff0cd547bc9309fe9b0dbda4b2",
       "value": 2464616.0
      }
     },
     "5eb61595d2a046f296a0bcffd06ec6c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5eed25b66fc442b982d2909fd38753a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "619e47a97d1a44ada7470df388b5901e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "629cdeafcdef48b6b87cfdb96c1c83a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_306b3b70c858433c9b8d0daa113cec02",
       "max": 371146213.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70435785de7740eeaccf5393ff286ab3",
       "value": 371146213.0
      }
     },
     "633faf3fab4e463fb0e571e8a60c5721": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2115429dc9884258a06e2608482e33c1",
       "placeholder": "​",
       "style": "IPY_MODEL_28c174f839b149f1be31367085f14dec",
       "value": "spm.model: 100%"
      }
     },
     "6ede771eaa80453e958d80b70e5e46b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "70435785de7740eeaccf5393ff286ab3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "71fc90388cf5499196b9a244d7da6cb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "74a24e74b62949a999ed3dba2ce19023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ed98317f76449dab14a939c62a0b986",
        "IPY_MODEL_406119625eb14ebfbc960b2ba55ec6f2",
        "IPY_MODEL_98855b892e5b44c88e8e64a4c460582b"
       ],
       "layout": "IPY_MODEL_f332c1d3868e458bb95cda636c80d0ef"
      }
     },
     "756c71f1002d4123a9a3aa5e872aa965": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_949287a48c4c401e89399ed05e2aecf1",
       "placeholder": "​",
       "style": "IPY_MODEL_619e47a97d1a44ada7470df388b5901e",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 3.42MB/s]"
      }
     },
     "75db45b3c20d40258ee58f7f3846393d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7668db0b7cfd40fe840b0d453b858c2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ed98317f76449dab14a939c62a0b986": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2c17a0a3ad94a9baa6845565072be04",
       "placeholder": "​",
       "style": "IPY_MODEL_75db45b3c20d40258ee58f7f3846393d",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "8212a8b7389e430e88a7b55235436a1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_22892d586a994f349bae332fee7c6040",
        "IPY_MODEL_efd82f07b70740aa99d88784abddee38",
        "IPY_MODEL_b58a3b4f20ca42a4aaad43ffb78d4b3d"
       ],
       "layout": "IPY_MODEL_2ff719df56ac4f34834efe8839da96a6"
      }
     },
     "883066b28b91427f9a7e49a21a442e6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9101ad1168a1409991c58c2afd7a1b8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5eb61595d2a046f296a0bcffd06ec6c5",
       "placeholder": "​",
       "style": "IPY_MODEL_cb9722657fa9428d8475a31494d99ba6",
       "value": " 371M/371M [00:09&lt;00:00, 38.8MB/s]"
      }
     },
     "949287a48c4c401e89399ed05e2aecf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98855b892e5b44c88e8e64a4c460582b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5eed25b66fc442b982d2909fd38753a2",
       "placeholder": "​",
       "style": "IPY_MODEL_abc740f5efe7470c8b42a081ceb3a0b9",
       "value": " 52.0/52.0 [00:00&lt;00:00, 4.45kB/s]"
      }
     },
     "9d3af92e36834446a88d5b88fe5971d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3288efe84f0460da0e5da1ef2f2153c",
        "IPY_MODEL_629cdeafcdef48b6b87cfdb96c1c83a5",
        "IPY_MODEL_9101ad1168a1409991c58c2afd7a1b8b"
       ],
       "layout": "IPY_MODEL_220dc9fc707e45ecac697ef9da557059"
      }
     },
     "a2c17a0a3ad94a9baa6845565072be04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abc740f5efe7470c8b42a081ceb3a0b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b380ccff0cd547bc9309fe9b0dbda4b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b58a3b4f20ca42a4aaad43ffb78d4b3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e60eb5333fad4e1e9eb45eb9736b2dca",
       "placeholder": "​",
       "style": "IPY_MODEL_e7950943e81b40c8858893b83411128f",
       "value": " 579/579 [00:00&lt;00:00, 52.7kB/s]"
      }
     },
     "c3288efe84f0460da0e5da1ef2f2153c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35f12a23246c4767832c9d3ae22c25ff",
       "placeholder": "​",
       "style": "IPY_MODEL_71fc90388cf5499196b9a244d7da6cb7",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "c5b89257b59c4706bec3201288cbffd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_633faf3fab4e463fb0e571e8a60c5721",
        "IPY_MODEL_4672ef56860143b9abcaf266a235f505",
        "IPY_MODEL_756c71f1002d4123a9a3aa5e872aa965"
       ],
       "layout": "IPY_MODEL_883066b28b91427f9a7e49a21a442e6b"
      }
     },
     "cb9722657fa9428d8475a31494d99ba6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e32e78ed3486421cbdff9da87a3d6f84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e60eb5333fad4e1e9eb45eb9736b2dca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7950943e81b40c8858893b83411128f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec95a7dc4a034097bfda176df02429f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efd82f07b70740aa99d88784abddee38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc63e08a9769490bb0b4f5bbfcdf6634",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7dbe34d75544b7b9ffd87f7295a6518",
       "value": 579.0
      }
     },
     "f332c1d3868e458bb95cda636c80d0ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7dbe34d75544b7b9ffd87f7295a6518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fc63e08a9769490bb0b4f5bbfcdf6634": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
